#!/usr/bin/env python3
"""
–¢–µ—Å—Ç —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ NLP –∞–¥–∞–ø—Ç–µ—Ä–∞ —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –º–∞—Ç—á–µ—Ä–∞–º–∏ –∏ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–µ–π
"""

import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(os.path.join(os.path.dirname(__file__), 'app'))

def test_enhanced_nlp():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ NLP –∞–¥–∞–ø—Ç–µ—Ä–∞"""
    
    print("=== –¢–µ—Å—Ç —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ NLP Adapter ===\n")
    
    try:
        from nlp_adapter import NLPAdapter
        print("‚úÖ –£–ª—É—á—à–µ–Ω–Ω—ã–π NLPAdapter –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
    except ImportError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        return False
    
    # –°–æ–∑–¥–∞–µ–º –∞–¥–∞–ø—Ç–µ—Ä —Å –Ω–∏–∑–∫–∏–º –ø–æ—Ä–æ–≥–æ–º –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    print("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å confidence_threshold=0.5...")
    adapter = NLPAdapter(confidence_threshold=0.5)
    print("‚úÖ –£–ª—É—á—à–µ–Ω–Ω—ã–π NLP –∞–¥–∞–ø—Ç–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —É–ª—É—á—à–µ–Ω–∏–π
    test_texts = [
        # –¢–µ—Å—Ç –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –º–∞—Ç—á–µ—Ä–æ–≤
        "–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤–∏—á –°–∏–¥–æ—Ä–æ–≤ –ø–æ–¥–ø–∏—Å–∞–ª –¥–æ–∫—É–º–µ–Ω—Ç",
        "–ò.–ü. –°–∏–¥–æ—Ä–æ–≤ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –û–û–û \"–†–æ–≥–∞ –∏ –ö–æ–ø—ã—Ç–∞\"",
        
        # –¢–µ—Å—Ç PhraseMatcher
        "–ì–ª–∞–≤–Ω—ã–π –±—É—Ö–≥–∞–ª—Ç–µ—Ä –ø–æ–ª—É—á–∞–µ—Ç –∑–∞—Ä–ø–ª–∞—Ç—É 150000 —Ä—É–±–ª–µ–π",
        "–°–∏—Å—Ç–µ–º–Ω—ã–π –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä –Ω–∞—Å—Ç—Ä–æ–∏–ª —Å–µ—Ä–≤–µ—Ä",
        "–ü—Ä–æ–µ–∫—Ç –º–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É –∫–æ–º–∞–Ω–¥—ã",
        
        # –¢–µ—Å—Ç –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        "–í–ª–∞–¥–∏–º–∏—Ä –ø—Ä–∏–Ω–µ—Å –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –æ—Ç–¥–µ–ª –∫–∞–¥—Ä–æ–≤",
        "–ê–Ω–Ω–∞ –°–µ—Ä–≥–µ–µ–≤–Ω–∞ —Ä—É–∫–æ–≤–æ–¥–∏—Ç –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–æ–º –ø—Ä–æ–¥–∞–∂",
        
        # –¢–µ—Å—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π
        "–ü–ê–û \"–°–±–µ—Ä–±–∞–Ω–∫\" –∑–∞–∫–ª—é—á–∏–ª–æ –¥–æ–≥–æ–≤–æ—Ä —Å –ê–û \"–ì–∞–∑–ø—Ä–æ–º\"",
        "–ò–ü –ü–µ—Ç—Ä–æ–≤ –æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–æ–Ω–Ω—ã–µ —É—Å–ª—É–≥–∏",
        
        # –¢–µ—Å—Ç —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
        "–í—Ä–∞—á-—Ç–µ—Ä–∞–ø–µ–≤—Ç –ú–∞—Ä–∏—è –ò–≤–∞–Ω–æ–≤–Ω–∞ –ø–æ—Å—Ç–∞–≤–∏–ª–∞ –¥–∏–∞–≥–Ω–æ–∑ –ø–Ω–µ–≤–º–æ–Ω–∏—è",
        "–Æ—Ä–∏—Å—Ç –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –ø—Ä–∞–≤–∞ –∏–∑—É—á–∞–µ—Ç –∫–æ–º–º–µ—Ä—á–µ—Å–∫—É—é —Ç–∞–π–Ω—É",
        
        # –¢–µ—Å—Ç confidence threshold
        "–í—Å—Ç—Ä–µ—á–∞ —Å–æ—Å—Ç–æ–∏—Ç—Å—è –≤ –ú–æ—Å–∫–≤–µ –≤ –æ—Ñ–∏—Å–µ –∫–æ–º–ø–∞–Ω–∏–∏",
        "–ó–∞—Ä–ø–ª–∞—Ç–∞ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 80000 ‚ÇΩ –≤ –º–µ—Å—è—Ü"
    ]
    
    print(f"\nüîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ {len(test_texts)} —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö:\n")
    
    total_detections = 0
    method_stats = {}
    
    for i, text in enumerate(test_texts, 1):
        print(f"üìù –¢–µ—Å—Ç {i}: '{text}'")
        
        try:
            detections = adapter.find_sensitive_data(text)
            total_detections += len(detections)
            
            if detections:
                print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(detections)} –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π:")
                for detection in detections:
                    category = detection['category']
                    value = detection['original_value']
                    confidence = detection['confidence']
                    method = detection['method']
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–µ—Ç–æ–¥–æ–≤
                    if method not in method_stats:
                        method_stats[method] = 0
                    method_stats[method] += 1
                    
                    print(f"      - {category}: '{value}' (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f}, –º–µ—Ç–æ–¥: {method})")
            else:
                print(f"   ‚ùå –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                
        except Exception as e:
            print(f"   üí• –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            import traceback
            traceback.print_exc()
        
        print()
    
    print(f"üìä –ò—Ç–æ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {total_detections} –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π –≤ {len(test_texts)} —Ç–µ–∫—Å—Ç–∞—Ö")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–µ—Ç–æ–¥–æ–≤
    print(f"\nüîß –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–µ—Ç–æ–¥–æ–≤ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è:")
    for method, count in method_stats.items():
        print(f"   {method}: {count} –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–µ —Ñ—Ä–∞–∑—ã
    print(f"\nüìã –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –∫–∞—Å—Ç–æ–º–Ω—ã–µ —Ñ—Ä–∞–∑—ã:")
    for category, phrases in adapter.custom_phrases.items():
        print(f"   {category}: {len(phrases)} —Ñ—Ä–∞–∑")
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤
        examples = phrases[:3]
        print(f"      –ü—Ä–∏–º–µ—Ä—ã: {', '.join(examples)}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ confidence threshold
    print(f"\nüéØ –¢–µ–∫—É—â–∏–π –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {adapter.confidence_threshold}")
    
    return True

def test_confidence_threshold():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –ø–æ—Ä–æ–≥–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
    
    print("\n=== –¢–µ—Å—Ç –ø–æ—Ä–æ–≥–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ ===\n")
    
    from nlp_adapter import NLPAdapter
    
    test_text = "–ü—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç –ò–≤–∞–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –∫–æ–º–ø–∞–Ω–∏–∏ –∏ –ø–æ–ª—É—á–∞–µ—Ç –∑–∞—Ä–ø–ª–∞—Ç—É 100000 —Ä—É–±–ª–µ–π"
    
    thresholds = [0.3, 0.5, 0.7, 0.9]
    
    for threshold in thresholds:
        print(f"üéØ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å –ø–æ—Ä–æ–≥–æ–º {threshold}:")
        adapter = NLPAdapter(confidence_threshold=threshold)
        
        detections = adapter.find_sensitive_data(test_text)
        print(f"   –ù–∞–π–¥–µ–Ω–æ {len(detections)} –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π")
        
        for detection in detections:
            confidence = detection['confidence']
            category = detection['category']
            value = detection['original_value']
            print(f"      - {category}: '{value}' (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f})")
        print()

if __name__ == "__main__":
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ NLP Service\n")
    
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ—Å—Ç
    success = test_enhanced_nlp()
    
    if success:
        # –¢–µ—Å—Ç –ø–æ—Ä–æ–≥–æ–≤
        test_confidence_threshold()
        
        print("\nüéâ –í—Å–µ —Ç–µ—Å—Ç—ã —É–ª—É—á—à–µ–Ω–∏–π –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        print("üöÄ –£–ª—É—á—à–µ–Ω–Ω—ã–π NLP Service –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
        print("\nüí° –£–ª—É—á—à–µ–Ω–∏—è:")
        print("   ‚úÖ –ö–∞—Å—Ç–æ–º–Ω—ã–µ PhraseMatcher –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤")
        print("   ‚úÖ –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å pymorphy3")
        print("   ‚úÖ –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏")
        print("   ‚úÖ –£–ª—É—á—à–µ–Ω–Ω–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π")
    else:
        print("\nüí• –ï—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º NLP –∞–¥–∞–ø—Ç–µ—Ä–æ–º")