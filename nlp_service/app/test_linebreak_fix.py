#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ —Å—Ç—Ä–æ–∫ –≤ PhraseMatcher
"""

import sys
import os
sys.path.append(os.path.dirname(__file__))

from nlp_adapter import NLPAdapter
from text_normalizer import TextNormalizer

def test_line_break_fix():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ —Å—Ç—Ä–æ–∫"""
    
    print("=" * 80)
    print("üß™ –¢–ï–°–¢ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø –ü–†–û–ë–õ–ï–ú–´ –° –ü–ï–†–ï–ù–û–°–ê–ú–ò –°–¢–†–û–ö")
    print("=" * 80)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–¥–∞–ø—Ç–µ—Ä
    adapter = NLPAdapter()
    
    # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ —Å—Ç—Ä–æ–∫
    test_text_with_linebreaks = """
    –°–æ–≥–ª–∞—Å–Ω–æ –ø–∏—Å—å–º—É –æ—Ç –ú–ò–ù–ò–°–¢–ï–†–°–¢–í–û –ò–ù–§–û–†–ú–ê–¶–ò–û–ù–ù–û–ì–û –†–ê–ó–í–ò–¢–ò–Ø –ò –°–í–Ø–ó–ò
    –ü–ï–†–ú–°–ö–û–ì–û –ö–†–ê–Ø –æ—Ç 15.01.2024 ‚Ññ 123 —Ç—Ä–µ–±—É–µ—Ç—Å—è...
    
    –¢–∞–∫–∂–µ –î–ï–ü–ê–†–¢–ê–ú–ï–ù–¢ –û–ë–†–ê–ó–û–í–ê–ù–ò–Ø –ò –ù–ê–£–ö–ò
    –ö–ò–†–û–í–°–ö–û–ô –û–ë–õ–ê–°–¢–ò —Å–æ–æ–±—â–∏–ª...
    """
    
    # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤
    test_text_clean = """
    –°–æ–≥–ª–∞—Å–Ω–æ –ø–∏—Å—å–º—É –æ—Ç –ú–ò–ù–ò–°–¢–ï–†–°–¢–í–û –ò–ù–§–û–†–ú–ê–¶–ò–û–ù–ù–û–ì–û –†–ê–ó–í–ò–¢–ò–Ø –ò –°–í–Ø–ó–ò –ü–ï–†–ú–°–ö–û–ì–û –ö–†–ê–Ø –æ—Ç 15.01.2024 ‚Ññ 123 —Ç—Ä–µ–±—É–µ—Ç—Å—è...
    
    –¢–∞–∫–∂–µ –î–ï–ü–ê–†–¢–ê–ú–ï–ù–¢ –û–ë–†–ê–ó–û–í–ê–ù–ò–Ø –ò –ù–ê–£–ö–ò –ö–ò–†–û–í–°–ö–û–ô –û–ë–õ–ê–°–¢–ò —Å–æ–æ–±—â–∏–ª...
    """
    
    print("üìù –ò–°–•–û–î–ù–´–ô –¢–ï–ö–°–¢ –° –ü–ï–†–ï–ù–û–°–ê–ú–ò:")
    print(repr(test_text_with_linebreaks))
    print()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä
    normalizer = TextNormalizer()
    normalized = normalizer.normalize_text(test_text_with_linebreaks)
    
    print("üîß –ù–û–†–ú–ê–õ–ò–ó–û–í–ê–ù–ù–´–ô –¢–ï–ö–°–¢:")
    print(repr(normalized))
    print()
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏
    print("üîç –û–ë–†–ê–ë–û–¢–ö–ê –¢–ï–ö–°–¢–ê –° –ü–ï–†–ï–ù–û–°–ê–ú–ò –°–¢–†–û–ö:")
    print("-" * 50)
    results_with_breaks = adapter.find_sensitive_data(test_text_with_linebreaks)
    
    print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results_with_breaks)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤:")
    for i, result in enumerate(results_with_breaks, 1):
        if result['category'] == 'government_org':
            start = result['position']['start']
            end = result['position']['end']
            found_text = test_text_with_linebreaks[start:end]
            print(f"   {i}. '{result['original_value']}' (–ø–æ–∑–∏—Ü–∏—è {start}-{end})")
            print(f"      –ú–µ—Ç–æ–¥: {result['method']}")
            print(f"      Confidence: {result['confidence']:.3f}")
            print(f"      –†–µ–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç: '{found_text}'")
            print()
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    print("\nüîç –û–ë–†–ê–ë–û–¢–ö–ê –ß–ò–°–¢–û–ì–û –¢–ï–ö–°–¢–ê (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è):")
    print("-" * 50)
    results_clean = adapter.find_sensitive_data(test_text_clean)
    
    print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results_clean)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤:")
    for i, result in enumerate(results_clean, 1):
        if result['category'] == 'government_org':
            start = result['position']['start']
            end = result['position']['end']
            found_text = test_text_clean[start:end]
            print(f"   {i}. '{result['original_value']}' (–ø–æ–∑–∏—Ü–∏—è {start}-{end})")
            print(f"      –ú–µ—Ç–æ–¥: {result['method']}")
            print(f"      Confidence: {result['confidence']:.3f}")
            print(f"      –†–µ–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç: '{found_text}'")
            print()
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("üìä –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
    print("-" * 50)
    
    gov_orgs_with_breaks = [r for r in results_with_breaks if r['category'] == 'government_org']
    gov_orgs_clean = [r for r in results_clean if r['category'] == 'government_org']
    
    print(f"üèõÔ∏è –ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π (—Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏): {len(gov_orgs_with_breaks)}")
    print(f"üèõÔ∏è –ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π (—á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç): {len(gov_orgs_clean)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞—à–ª–∏ –ø–æ–ª–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
    full_names_found = []
    partial_names_found = []
    
    for result in gov_orgs_with_breaks:
        name_length = len(result['original_value'].split())
        if name_length >= 6:  # –ü–æ–ª–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –æ–±—ã—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–µ
            full_names_found.append(result['original_value'])
        else:
            partial_names_found.append(result['original_value'])
    
    print(f"üìè –ü–æ–ª–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –Ω–∞–π–¥–µ–Ω–æ: {len(full_names_found)}")
    for name in full_names_found:
        print(f"   ‚úÖ '{name}' ({len(name.split())} —Å–ª–æ–≤)")
    
    print(f"üìè –ß–∞—Å—Ç–∏—á–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –Ω–∞–π–¥–µ–Ω–æ: {len(partial_names_found)}")
    for name in partial_names_found:
        print(f"   ‚ö†Ô∏è '{name}' ({len(name.split())} —Å–ª–æ–≤)")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    if len(full_names_found) > len(partial_names_found):
        print("\nüéâ –£–°–ü–ï–•! –ë–æ–ª—å—à–µ –ø–æ–ª–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π, —á–µ–º —á–∞—Å—Ç–∏—á–Ω—ã—Ö")
    elif len(gov_orgs_with_breaks) > 0:
        print("\n‚ö†Ô∏è –ß–ê–°–¢–ò–ß–ù–û: –ù–∞–π–¥–µ–Ω—ã –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏, –Ω–æ –Ω—É–∂–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞")
    else:
        print("\n‚ùå –ù–ï–£–î–ê–ß–ê: –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    return results_with_breaks, results_clean


if __name__ == "__main__":
    test_line_break_fix()