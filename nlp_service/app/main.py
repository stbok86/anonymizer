#!/usr/bin/env python3
"""
NLP Service –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
–§–æ–∫—É—Å –Ω–∞ spaCy NER + –∫–∞—Å—Ç–æ–º–Ω—ã–µ –º–∞—Ç—á–µ—Ä—ã + –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import logging
import os
import sys

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from nlp_adapter import NLPAdapter

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="NLP Service", version="1.0.0")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä NLP –∞–¥–∞–ø—Ç–µ—Ä–∞
nlp_adapter = None

# Pydantic –º–æ–¥–µ–ª–∏ –¥–ª—è API
class TextBlock(BaseModel):
    """–ë–ª–æ–∫ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    content: str
    block_id: str
    block_type: str = "text"

class AnalyzeRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤"""
    blocks: List[TextBlock]
    options: Optional[Dict[str, Any]] = {}

class Detection(BaseModel):
    """–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""
    category: str
    original_value: str
    confidence: float
    position: Dict[str, int]
    method: str
    uuid: str
    block_id: str

class AnalyzeResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞"""
    success: bool
    detections: List[Detection]
    total_detections: int
    blocks_processed: int
    error: Optional[str] = None

@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"""
    global nlp_adapter
    
    try:
        logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è NLP Service...")
        
        # –°–æ–∑–¥–∞–µ–º NLP –∞–¥–∞–ø—Ç–µ—Ä
        nlp_adapter = NLPAdapter()
        
        logger.info("‚úÖ NLP Service —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ NLP Service: {e}")
        raise e

@app.get("/healthz")
def healthz():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    return {"status": "ok", "service": "nlp-service"}

@app.get("/readyz")
def readyz():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–∞"""
    global nlp_adapter
    
    if nlp_adapter is None:
        raise HTTPException(status_code=503, detail="NLP adapter not initialized")
    
    return {"status": "ready", "service": "nlp-service"}

@app.post("/analyze", response_model=AnalyzeResponse)
async def analyze_blocks(request: AnalyzeRequest):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    
    Args:
        request: –ó–∞–ø—Ä–æ—Å —Å –±–ª–æ–∫–∞–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    """
    global nlp_adapter
    
    if nlp_adapter is None:
        raise HTTPException(
            status_code=503, 
            detail="NLP adapter not initialized"
        )
    
    try:
        logger.info(f"üìù –ê–Ω–∞–ª–∏–∑ {len(request.blocks)} –±–ª–æ–∫–æ–≤")
        
        all_detections = []
        blocks_processed = 0
        
        for block in request.blocks:
            try:
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –±–ª–æ–∫–∞
                block_detections = nlp_adapter.find_sensitive_data(block.content)
                
                # –î–æ–±–∞–≤–ª—è–µ–º block_id –∫ –∫–∞–∂–¥–æ–º—É –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—é
                for detection in block_detections:
                    detection['block_id'] = block.block_id
                    all_detections.append(Detection(**detection))
                
                blocks_processed += 1
                
                logger.debug(f"–ë–ª–æ–∫ {block.block_id}: –Ω–∞–π–¥–µ–Ω–æ {len(block_detections)} –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π")
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –±–ª–æ–∫–∞ {block.block_id}: {e}")
                continue
        
        logger.info(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(all_detections)} –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π –≤ {blocks_processed} –±–ª–æ–∫–∞—Ö")
        
        return AnalyzeResponse(
            success=True,
            detections=all_detections,
            total_detections=len(all_detections),
            blocks_processed=blocks_processed
        )
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return AnalyzeResponse(
            success=False,
            detections=[],
            total_detections=0,
            blocks_processed=0,
            error=str(e)
        )

@app.get("/patterns")
async def get_patterns():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö"""
    global nlp_adapter
    
    if nlp_adapter is None:
        raise HTTPException(
            status_code=503,
            detail="NLP adapter not initialized"  
        )
    
    patterns_info = {}
    
    for category, configs in nlp_adapter.pattern_configs.items():
        patterns_info[category] = {
            'count': len(configs),
            'types': list(set(config['pattern_type'] for config in configs)),
            'descriptions': [config['description'] for config in configs]
        }
    
    return {
        "total_categories": len(patterns_info),
        "patterns": patterns_info
    }

@app.get("/patterns/{category}")
async def get_category_patterns(category: str):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
    global nlp_adapter
    
    if nlp_adapter is None:
        raise HTTPException(
            status_code=503,
            detail="NLP adapter not initialized"
        )
    
    if category not in nlp_adapter.pattern_configs:
        raise HTTPException(
            status_code=404,
            detail=f"Category '{category}' not found"
        )
    
    configs = nlp_adapter.pattern_configs[category]
    return {
        "category": category,
        "patterns": [
            {
                "pattern": config['pattern'],
                "type": config['pattern_type'], 
                "confidence": config['confidence'],
                "context_required": config['context_required'],
                "description": config['description']
            }
            for config in configs
        ]
    }

@app.get("/categories") 
async def get_categories():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
    global nlp_adapter
    
    if nlp_adapter is None:
        raise HTTPException(
            status_code=503,
            detail="NLP adapter not initialized"
        )
    
    categories = list(nlp_adapter.patterns.keys())
    
    return {
        "categories": categories,
        "total": len(categories)
    }

@app.post("/test")
async def test_analysis(text: str):
    """–¢–µ—Å—Ç–æ–≤—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞"""
    global nlp_adapter
    
    if nlp_adapter is None:
        raise HTTPException(
            status_code=503,
            detail="NLP adapter not initialized"
        )
    
    try:
        detections = nlp_adapter.find_sensitive_data(text)
        
        return {
            "text": text,
            "detections": detections,
            "count": len(detections)
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8006)
