#!/usr/bin/env python3
"""
–ü—Ä–∏–º–µ—Ä –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ spaCy NER –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π
"""

import spacy
from typing import List, Dict, Any
import re

class GovernmentOrgDetectorWithNER:
    """–î–µ—Ç–µ–∫—Ç–æ—Ä –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º spaCy NER"""
    
    def __init__(self):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä—É—Å—Å–∫—É—é –º–æ–¥–µ–ª—å spaCy
        self.nlp = spacy.load("ru_core_news_lg")
        
        # –°–ª–æ–≤–∞—Ä—å –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        self.gov_keywords = {
            '–º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ', '–¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç', '—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ', '—Å–ª—É–∂–±–∞', '–∞–≥–µ–Ω—Ç—Å—Ç–≤–æ',
            '–∫–æ–º–∏—Ç–µ—Ç', '–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏—è', '–ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ', '–¥—É–º–∞', '—Å–æ–≤–µ—Ç',
            '—Ñ–µ–¥–µ—Ä–∞–ª—å–Ω–∞—è', '—Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω–∞—è', '–º—É–Ω–∏—Ü–∏–ø–∞–ª—å–Ω–∞—è', '–≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–∞—è'
        }
        
        # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è
        self.gov_abbreviations = {
            '–º–≤–¥', '—Ñ–Ω—Å', '—Ñ—Å–±', '–º—á—Å', '—Å–≤—Ä', '–≥—É –º–≤–¥', '—É–º–≤–¥',
            '—Ä–æ—Å–∫–æ–º–Ω–∞–¥–∑–æ—Ä', '—Ä–æ—Å—Ä–µ–µ—Å—Ç—Ä', '—Ä–æ—Å—Ç—É—Ä–∏–∑–º', '—Ä–æ—Å—Å—Ç–∞—Ç',
            '–º–∏–Ω–∑–¥—Ä–∞–≤', '–º–∏–Ω–æ–±—Ä–Ω–∞—É–∫–∏', '–º–∏–Ω—Ñ–∏–Ω', '–º–∏–Ω—ç–∫–æ–Ω–æ–º—Ä–∞–∑–≤–∏—Ç–∏—è'
        }
    
    def detect_government_orgs(self, text: str) -> List[Dict[str, Any]]:
        """
        –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É—è spaCy NER + —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é
        
        Args:
            text: –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π
        """
        doc = self.nlp(text)
        detections = []
        
        # 1. –ò—Å–ø–æ–ª—å–∑—É–µ–º spaCy NER –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤—Å–µ—Ö –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π
        for ent in doc.ents:
            if ent.label_ == "ORG":  # –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –ø–æ spaCy
                
                # 2. –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
                if self._is_government_org(ent.text):
                    detection = {
                        'category': 'government_org',
                        'original_value': ent.text,
                        'confidence': self._calculate_ner_confidence(ent),
                        'position': {'start': ent.start_char, 'end': ent.end_char},
                        'method': 'spacy_ner_filtered',
                        'detection_reason': self._get_detection_reason(ent.text)
                    }
                    detections.append(detection)
        
        return detections
    
    def _is_government_org(self, org_name: str) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–π
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç–≤—Ä–∏—Å—Ç–∏–∫:
        1. –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (–º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ, –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç...)
        2. –ò–∑–≤–µ—Å—Ç–Ω—ã–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è (–ú–í–î, –§–ù–°...)
        3. –ü–∞—Ç—Ç–µ—Ä–Ω—ã –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π
        """
        org_lower = org_name.lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è
        if org_lower in self.gov_abbreviations:
            return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        for keyword in self.gov_keywords:
            if keyword in org_lower:
                return True
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        gov_patterns = [
            r'\b(—Ñ–∑|—Ä—Ñ|—Ä–æ—Å—Å–∏–π—Å–∫–∞—è\s+—Ñ–µ–¥–µ—Ä–∞—Ü–∏—è)\b',
            r'\b\w+\s*(–æ–±–ª–∞—Å—Ç–∏|–∫—Ä–∞—è|—Ä–µ—Å–ø—É–±–ª–∏–∫–∏)\b',
            r'\b–≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω\w+',
            r'\b—Ñ–µ–¥–µ—Ä–∞–ª—å–Ω\w+',
        ]
        
        for pattern in gov_patterns:
            if re.search(pattern, org_lower):
                return True
        
        return False
    
    def _calculate_ner_confidence(self, ent) -> float:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è NER –¥–µ—Ç–µ–∫—Ü–∏–∏
        
        –£—á–∏—Ç—ã–≤–∞–µ—Ç:
        - –ë–∞–∑–æ–≤—É—é confidence –æ—Ç spaCy
        - –î–ª–∏–Ω—É –Ω–∞–∑–≤–∞–Ω–∏—è (–¥–ª–∏–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –æ–±—ã—á–Ω–æ —Ç–æ—á–Ω–µ–µ)
        - –ù–∞–ª–∏—á–∏–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        """
        base_confidence = 0.75  # –ë–∞–∑–æ–≤–∞—è –¥–ª—è spaCy ORG
        
        # –ë–æ–Ω—É—Å –∑–∞ –¥–ª–∏–Ω—É (–±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –æ–±—ã—á–Ω–æ —Ç–æ—á–Ω–µ–µ)
        length_bonus = min(0.15, len(ent.text.split()) * 0.03)
        
        # –ë–æ–Ω—É—Å –∑–∞ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        keyword_bonus = 0.0
        org_lower = ent.text.lower()
        
        high_confidence_words = ['–º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ', '—Ñ–µ–¥–µ—Ä–∞–ª—å–Ω–∞—è —Å–ª—É–∂–±–∞', '—Ñ–µ–¥–µ—Ä–∞–ª—å–Ω–æ–µ –∞–≥–µ–Ω—Ç—Å—Ç–≤–æ']
        medium_confidence_words = ['–¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç', '—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ', '–∫–æ–º–∏—Ç–µ—Ç']
        
        for word in high_confidence_words:
            if word in org_lower:
                keyword_bonus = 0.15
                break
        
        if keyword_bonus == 0:
            for word in medium_confidence_words:
                if word in org_lower:
                    keyword_bonus = 0.08
                    break
        
        return min(0.95, base_confidence + length_bonus + keyword_bonus)
    
    def _get_detection_reason(self, org_name: str) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–∏—á–∏–Ω—É, –ø–æ –∫–æ—Ç–æ—Ä–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Å—á–∏—Ç–∞–µ—Ç—Å—è –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–π"""
        org_lower = org_name.lower()
        
        if org_lower in self.gov_abbreviations:
            return "known_government_abbreviation"
        
        for keyword in self.gov_keywords:
            if keyword in org_lower:
                return f"contains_keyword_{keyword}"
        
        return "pattern_match"

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def demonstrate_ner_improvement():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ spaCy NER –ø–æ–¥—Ö–æ–¥–∞"""
    
    detector = GovernmentOrgDetectorWithNER()
    
    test_texts = [
        "–†–æ—Å–∫–æ–º–Ω–∞–¥–∑–æ—Ä –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª —Å–∞–π—Ç –∫–æ–º–ø–∞–Ω–∏–∏ –û–û–û –†–æ–≥–∞ –∏ –ö–æ–ø—ã—Ç–∞.",
        "–ú–í–î –†–§ –∏ –§–ù–° –†–æ—Å—Å–∏–∏ –ø—Ä–æ–≤–æ–¥—è—Ç —Å–æ–≤–º–µ—Å—Ç–Ω—ã–µ —Ä–µ–π–¥—ã.",
        "–ú–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ü–µ—Ä–º—Å–∫–æ–≥–æ –∫—Ä–∞—è –æ–±—ä—è–≤–∏–ª–æ —Ç–µ–Ω–¥–µ—Ä.",
        "–î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≥. –ú–æ—Å–∫–≤—ã —É—Ç–≤–µ—Ä–¥–∏–ª –Ω–æ–≤—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã.",
        "–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏—è –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –†–§ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª–∞ —É–∫–∞–∑."
    ]
    
    print("üîç –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –†–ê–ë–û–¢–´ spaCy NER –î–õ–Ø –ì–û–°–£–î–ê–†–°–¢–í–ï–ù–ù–´–• –û–†–ì–ê–ù–ò–ó–ê–¶–ò–ô")
    print("=" * 80)
    
    for i, text in enumerate(test_texts, 1):
        print(f"\nüìù –¢–µ–∫—Å—Ç {i}: {text}")
        detections = detector.detect_government_orgs(text)
        
        if detections:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(detections)} –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π:")
            for det in detections:
                print(f"   ‚Ä¢ {det['original_value']} (confidence: {det['confidence']:.2f})")
                print(f"     –ü—Ä–∏—á–∏–Ω–∞: {det['detection_reason']}")
        else:
            print("‚ùå –ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

if __name__ == "__main__":
    demonstrate_ner_improvement()