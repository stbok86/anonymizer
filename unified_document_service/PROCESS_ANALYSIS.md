# üìã –ê–ù–ê–õ–ò–ó –ü–†–û–¶–ï–°–°–ê –ê–ù–û–ù–ò–ú–ò–ó–ê–¶–ò–ò –î–û–ö–£–ú–ï–ù–¢–û–í

## üèóÔ∏è –ê–†–•–ò–¢–ï–ö–¢–£–†–ê –°–ò–°–¢–ï–ú–´

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         UNIFIED DOCUMENT SERVICE                      ‚îÇ
‚îÇ                         (–ü–æ—Ä—Ç 8009)                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚ñº               ‚ñº               ‚ñº
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ NLP Service  ‚îÇ  ‚îÇ Rule Engine  ‚îÇ  ‚îÇ  Frontend    ‚îÇ
          ‚îÇ  (–ü–æ—Ä—Ç 8006) ‚îÇ  ‚îÇ  (–ü–æ—Ä—Ç 8003) ‚îÇ  ‚îÇ  (–ü–æ—Ä—Ç 8501) ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîÑ –ü–û–õ–ù–´–ô –¶–ò–ö–õ –ê–ù–û–ù–ò–ú–ò–ó–ê–¶–ò–ò: –ü–û–®–ê–ì–û–í–û–ï –û–ü–ò–°–ê–ù–ò–ï

### **üìç –¢–û–ß–ö–ê –í–•–û–î–ê: `/anonymize_full` API**

**–°–µ—Ä–≤–∏—Å:** `Unified Document Service`  
**–§–∞–π–ª:** `unified_document_service/app/main.py`  
**–ú–µ—Ç–æ–¥:** `POST /anonymize_full`

**–í—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:**
```python
{
    "file": UploadFile,                          # DOCX –¥–æ–∫—É–º–µ–Ω—Ç
    "patterns_file": str,                        # –ü—É—Ç—å –∫ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: patterns/sensitive_patterns.xlsx)
    "generate_excel_report": bool = True,        # –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å Excel –æ—Ç—á—ë—Ç
    "generate_json_ledger": bool = True          # –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å JSON –∂—É—Ä–Ω–∞–ª
}
```

**–í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:**
```python
{
    "status": "success",
    "statistics": {...},
    "files_base64": {
        "anonymized_document_base64": str,       # Base64 –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        "excel_report_base64": str,              # Base64 Excel –æ—Ç—á—ë—Ç–∞
        "json_ledger_base64": str                # Base64 JSON –∂—É—Ä–Ω–∞–ª–∞
    }
}
```

---

## üéØ –≠–¢–ê–ü 1: –ó–ê–ì–†–£–ó–ö–ê –ò –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø

### **1.1. –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤**
```python
# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
tmp_input = tempfile.NamedTemporaryFile(delete=False, suffix=".docx")
input_path = tmp_input.name

# –°–æ–∑–¥–∞—ë–º –ø—É—Ç–∏ –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
output_path = f"{filename_base}_anonymized.docx"
excel_path = f"{filename_base}_report.xlsx"
json_path = f"{filename_base}_ledger.json"
```

### **1.2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FullAnonymizer**
```python
anonymizer = FullAnonymizer(patterns_path="patterns/sensitive_patterns.xlsx")
```

**–ß—Ç–æ —Å–æ–∑–¥–∞—ë—Ç—Å—è:**
- `BlockBuilder()` ‚Äî –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±–ª–æ–∫–∏ –∏–∑ DOCX
- `RuleAdapter()` ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ—Ç regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ Excel
- `FormatterApplier()` ‚Äî –ø—Ä–∏–º–µ–Ω—è–µ—Ç –∑–∞–º–µ–Ω—ã —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- `UUIDMapper()` ‚Äî –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ UUID

---

## üéØ –≠–¢–ê–ü 2: –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –ë–õ–û–ö–û–í –î–û–ö–£–ú–ï–ù–¢–ê

**–°–µ—Ä–≤–∏—Å:** `Unified Document Service`  
**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç:** `BlockBuilder`  
**–§–∞–π–ª:** `unified_document_service/app/block_builder.py`

### **2.1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞**
```python
doc = Document(input_path)  # python-docx –±–∏–±–ª–∏–æ—Ç–µ–∫–∞
blocks = self.block_builder.build_blocks(doc)
```

### **2.2. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –±–ª–æ–∫–æ–≤**
```python
# –ö–∞–∂–¥—ã–π –±–ª–æ–∫ —Å–æ–¥–µ—Ä–∂–∏—Ç:
{
    "block_id": str,           # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID: "paragraph_0", "table_1", "header_sdt_2_0"
    "text": str,               # –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –±–ª–æ–∫–∞
    "content": str,            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –ø–æ–ª–µ –¥–ª—è —Ç–µ–∫—Å—Ç–∞
    "element": object,         # –°—Å—ã–ª–∫–∞ –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç DOCX (Paragraph, Table, _Element)
    "type": str                # –¢–∏–ø: "paragraph", "table", "header", "header_sdt", "footer"
}
```

### **2.3. –¢–∏–ø—ã –∏–∑–≤–ª–µ–∫–∞–µ–º—ã—Ö –±–ª–æ–∫–æ–≤**

| –¢–∏–ø –±–ª–æ–∫–∞ | –ò—Å—Ç–æ—á–Ω–∏–∫ | –ü—Ä–∏–º–µ—Ä block_id | Element Type |
|-----------|----------|-----------------|--------------|
| **–ü–∞—Ä–∞–≥—Ä–∞—Ñ** | `doc.paragraphs` | `paragraph_0` | `docx.text.paragraph.Paragraph` |
| **–¢–∞–±–ª–∏—Ü–∞** | `doc.tables` | `table_0` | `docx.table.Table` |
| **–ó–∞–≥–æ–ª–æ–≤–æ–∫** | `section.header.paragraphs` | `header_1_0` | `docx.text.paragraph.Paragraph` |
| **SDT –∑–∞–≥–æ–ª–æ–≤–∫–∞** | `section.header._element.xpath` | `header_sdt_1_0` | `lxml.etree._Element` |
| **–ü–æ–¥–≤–∞–ª** | `section.footer.paragraphs` | `footer_1_0` | `docx.text.paragraph.Paragraph` |

**–ü—Ä–∏–º–µ—Ä:**
```python
blocks = [
    {
        "block_id": "header_sdt_1_0",
        "text": "PAGE 6 –ï–ò–°–£–§–•–î.13/–û–ö-2023.3.–ü–ú.1 312822699534",
        "element": <lxml.etree._Element>,
        "type": "header_sdt"
    },
    {
        "block_id": "paragraph_0",
        "text": "–ú–ò–ù–ò–°–¢–ï–†–°–¢–í–û –ò–ù–§–û–†–ú–ê–¶–ò–û–ù–ù–û–ì–û –†–ê–ó–í–ò–¢–ò–Ø –ò –°–í–Ø–ó–ò",
        "element": <Paragraph object>,
        "type": "paragraph"
    },
    {
        "block_id": "table_0",
        "text": "–£–¢–í–ï–†–ñ–î–ê–Æ | –£–¢–í–ï–†–ñ–î–ê–Æ\n–ù–∞—á–∞–ª—å–Ω–∏–∫...",
        "element": <Table object>,
        "type": "table"
    }
]
```

---

## üéØ –≠–¢–ê–ü 3: –î–ï–¢–ï–ö–¶–ò–Ø –ß–£–í–°–¢–í–ò–¢–ï–õ–¨–ù–´–• –î–ê–ù–ù–´–•

### **3.1. Rule Engine: Regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã**

**–°–µ—Ä–≤–∏—Å:** `Unified Document Service`  
**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç:** `RuleAdapter`  
**–§–∞–π–ª:** `unified_document_service/app/rule_adapter.py`

**–û–±—Ä–∞–±–æ—Ç–∫–∞:**
```python
processed_blocks = self.rule_engine.apply_rules_to_blocks(blocks)

# –î–ª—è –ö–ê–ñ–î–û–ì–û –±–ª–æ–∫–∞ –æ—Ç–¥–µ–ª—å–Ω–æ:
for block in blocks:
    text = block.get('text', '')
    regex_matches = self._find_regex_matches(text)  # ‚Üê Regex –Ω–∞ —Ç–µ–∫—Å—Ç –û–î–ù–û–ì–û –±–ª–æ–∫–∞
    block['sensitive_patterns'] = regex_matches
```

**–ò—Å—Ç–æ—á–Ω–∏–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤:**  
`unified_document_service/patterns/sensitive_patterns.xlsx`

**–§–æ—Ä–º–∞—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –≤ Excel:**
| category | pattern | confidence | description |
|----------|---------|------------|-------------|
| person_name | `([–ê-–Ø–Å]\.\s?[–ê-–Ø–Å]\.\s?[–ê-–Ø–Å–∞-—è—ë]+)` | 0.9 | –§–ò–û —Å –∏–Ω–∏—Ü–∏–∞–ª–∞–º–∏ |
| inn | `(\d{10}\|\d{12})` | 1.0 | –ò–ù–ù 10 –∏–ª–∏ 12 —Ü–∏—Ñ—Ä |
| email | `[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}` | 1.0 | Email –∞–¥—Ä–µ—Å |
| contract_number | `–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω(—ã–π\|–æ–≥–æ\|–æ–º—É) –∫–æ–Ω—Ç—Ä–∞–∫—Ç(–∞\|—É).*?‚Ññ\s*[\d/–ê-–Ø-]+` | 0.95 | –ì–æ—Å. –∫–æ–Ω—Ç—Ä–∞–∫—Ç |

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
```python
rule_engine_matches = [
    {
        "block_id": "table_0",
        "original_value": "–ö. –°. –ú—è—Å–Ω–∏–∫–æ–≤",
        "position": {"start": 233, "end": 247},
        "element": <Table object>,
        "category": "person_name",
        "confidence": 0.9,
        "source": "rule_engine",
        "method": "regex"
    }
]
```

---

### **3.2. NLP Service: AI-–¥–µ—Ç–µ–∫—Ü–∏—è**

**–°–µ—Ä–≤–∏—Å:** `NLP Service` (–≤–Ω–µ—à–Ω–∏–π –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å)  
**–ü–æ—Ä—Ç:** 8006  
**Endpoint:** `POST /analyze`

**–û–±—Ä–∞–±–æ—Ç–∫–∞ (–ü–û–ë–õ–û–ß–ù–ê–Ø —Å –Ω–µ–¥–∞–≤–Ω–µ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è):**
```python
# –î–û –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è: –æ—Ç–ø—Ä–∞–≤–ª—è–ª—Å—è –≤–µ—Å—å –¥–æ–∫—É–º–µ–Ω—Ç —Ü–µ–ª–∏–∫–æ–º
# –ü–û–°–õ–ï –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è: –∫–∞–∂–¥—ã–π –±–ª–æ–∫ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ

for block in blocks:
    block_text = block.get('text', '')
    if not block_text.strip():
        continue
    
    # –í—ã–∑–æ–≤ NLP Service –¥–ª—è –û–î–ù–û–ì–û –±–ª–æ–∫–∞
    block_detections = self._call_nlp_service(block_text)
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–π —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ –±–ª–æ–∫—É
    for detection in block_detections:
        nlp_matches.append({
            "block_id": block["block_id"],
            "original_value": detection["original_value"],
            "position": detection["position"],  # –£–∂–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±–ª–æ–∫–∞!
            "element": block.get("element"),
            "category": detection["category"],
            "confidence": detection["confidence"],
            "source": "nlp_service",
            "method": detection["method"]
        })
```

**–ó–∞–ø—Ä–æ—Å –∫ NLP Service:**
```python
# –ú–µ—Ç–æ–¥: _call_nlp_service(text: str)
payload = {
    "blocks": [
        {
            "content": text,           # –¢–µ–∫—Å—Ç –û–î–ù–û–ì–û –±–ª–æ–∫–∞
            "block_id": "doc_block_1",
            "block_type": "text"
        }
    ],
    "options": {}
}

response = requests.post(
    "http://localhost:8006/analyze",
    json=payload,
    timeout=30
)
```

**–û—Ç–≤–µ—Ç –æ—Ç NLP Service:**
```python
{
    "success": true,
    "detections": [
        {
            "category": "organization",
            "original_value": "–ú–ò–ù–ò–°–¢–ï–†–°–¢–í–û –ò–ù–§–û–†–ú–ê–¶–ò–û–ù–ù–û–ì–û –†–ê–ó–í–ò–¢–ò–Ø –ò –°–í–Ø–ó–ò",
            "confidence": 1.0,
            "position": {"start": 0, "end": 45},  # –ü–æ–∑–∏—Ü–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±–ª–æ–∫–∞
            "method": "regex",
            "uuid": "generated-uuid",
            "anonymized_text": null,
            "block_id": "doc_block_1"
        }
    ],
    "total_detections": 1,
    "blocks_processed": 1
}
```

**–ú–µ—Ç–æ–¥—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ NLP Service:**
- `regex` ‚Äî —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –∏–∑ nlp_patterns.json
- `custom_matcher` ‚Äî spaCy Matcher (–ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã)
- `spaced_abbreviation` ‚Äî –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã —Å –ø—Ä–æ–±–µ–ª–∞–º–∏ (–ï–ò–° –£–§–•–î –ü–ö)
- `complex_abbreviation` ‚Äî —Å–ª–æ–∂–Ω—ã–µ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã (–ï–ò–°–£–§–•–î)
- `information_system_regex` ‚Äî –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã

**–§–∞–π–ª –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ NLP:**  
`nlp_service/patterns/nlp_patterns.json` (31 –ø–∞—Ç—Ç–µ—Ä–Ω)

---

### **3.3. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤**

```python
# –ù–∞—á–∏–Ω–∞–µ–º —Å NLP (–±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ)
all_matches = nlp_matches.copy()

# –î–æ–±–∞–≤–ª—è–µ–º Rule Engine –¥–µ—Ç–µ–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –ù–ï –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è —Å NLP
for re_match in rule_engine_matches:
    is_duplicate = False
    for nlp_match in nlp_matches:
        if (re_match['block_id'] == nlp_match['block_id'] and
            positions_overlap(re_match['position'], nlp_match['position'])):
            is_duplicate = True
            break
    
    if not is_duplicate:
        all_matches.append(re_match)

# –ò—Ç–æ–≥–æ: —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∏–∑ –æ–±–æ–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
print(f"–ù–∞–π–¥–µ–Ω–æ: Rule Engine={len(rule_engine_matches)}, NLP={len(nlp_matches)}")
print(f"–ò—Ç–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {len(all_matches)}")
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏—è:**
```python
all_matches = [
    # NLP –¥–µ—Ç–µ–∫—Ü–∏–∏
    {
        "block_id": "paragraph_0",
        "original_value": "–ú–ò–ù–ò–°–¢–ï–†–°–¢–í–û –ò–ù–§–û–†–ú–ê–¶–ò–û–ù–ù–û–ì–û –†–ê–ó–í–ò–¢–ò–Ø –ò –°–í–Ø–ó–ò",
        "position": {"start": 0, "end": 45},
        "element": <Paragraph>,
        "category": "organization",
        "confidence": 1.0,
        "source": "nlp_service",
        "method": "regex"
    },
    # Rule Engine –¥–µ—Ç–µ–∫—Ü–∏–∏ (–Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏–µ—Å—è —Å NLP)
    {
        "block_id": "table_0",
        "original_value": "312822699534",
        "position": {"start": 450, "end": 462},
        "element": <Table>,
        "category": "inn",
        "confidence": 1.0,
        "source": "rule_engine",
        "method": "regex"
    }
]
```

---

## üéØ –≠–¢–ê–ü 4: –ü–†–ò–ú–ï–ù–ï–ù–ò–ï –ó–ê–ú–ï–ù

**–°–µ—Ä–≤–∏—Å:** `Unified Document Service`  
**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç:** `FormatterApplier`  
**–§–∞–π–ª:** `unified_document_service/app/formatter_applier.py`

### **4.1. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–º–µ–Ω —Å UUID**

```python
# –ú–µ—Ç–æ–¥: apply_replacements_to_document(doc, all_matches)
normalized_replacements = self._normalize_replacements_with_centralized_uuids(all_matches)
```

**–ì–µ–Ω–µ—Ä–∞—Ü–∏—è UUID (–¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Å—Ç–∏—á–µ—Å–∫–∞—è):**
```python
# –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è UUIDMapper
uuid = uuid_mapper.get_uuid_for_text(original_value, category)

# –ê–ª–≥–æ—Ä–∏—Ç–º:
namespace = UUID("document-anonymization-namespace")
hash_input = f"{original_value.lower()}_{category}"
uuid = uuid5(namespace, hash_input)

# –ü—Ä–∏–º–µ—Ä:
original_value = "–ú–ò–ù–ò–°–¢–ï–†–°–¢–í–û –ò–ù–§–û–†–ú–ê–¶–ò–û–ù–ù–û–ì–û –†–ê–ó–í–ò–¢–ò–Ø –ò –°–í–Ø–ó–ò"
category = "organization"
‚Üí UUID: "5b407955-d6e1-59ab-a5f5-50f38ec7291b"
```

### **4.2. –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–∞–º–µ–Ω –ø–æ –±–ª–æ–∫–∞–º**

```python
replacements_by_block = {}
for replacement in all_matches:
    block_id = replacement.get('block_id')
    if block_id not in replacements_by_block:
        replacements_by_block[block_id] = []
    replacements_by_block[block_id].append(replacement)

# –†–µ–∑—É–ª—å—Ç–∞—Ç:
# {
#     "paragraph_0": [match1, match2],
#     "table_0": [match3, match4, match5]
# }
```

### **4.3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞**

```python
for block_id, block_replacements in replacements_by_block.items():
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∑–∞–º–µ–Ω—ã –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ –ø–æ–∑–∏—Ü–∏–π
    # (—á—Ç–æ–±—ã –∑–∞–º–µ–Ω—ã –≤ –∫–æ–Ω—Ü–µ –Ω–µ —Å–¥–≤–∏–≥–∞–ª–∏ –ø–æ–∑–∏—Ü–∏–∏ –¥–ª—è –∑–∞–º–µ–Ω –≤ –Ω–∞—á–∞–ª–µ)
    block_replacements.sort(key=lambda x: x['position']['start'], reverse=True)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∑–∞–º–µ–Ω—ã –∫ –±–ª–æ–∫—É
    block_stats = self._apply_replacements_to_block(block_replacements)
```

### **4.4. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–¥–Ω–æ–π –∑–∞–º–µ–Ω—ã**

```python
# –ú–µ—Ç–æ–¥: _apply_single_replacement(replacement)

element = replacement.get('element')           # –°—Å—ã–ª–∫–∞ –Ω–∞ DOCX —ç–ª–µ–º–µ–Ω—Ç
original_value = replacement.get('original_value')
replacement_value = replacement.get('uuid')    # UUID –¥–ª—è –∑–∞–º–µ–Ω—ã
position = replacement.get('position')

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —ç–ª–µ–º–µ–Ω—Ç–∞ –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥:

if 'lxml' in str(type(element)):
    # SDT —ç–ª–µ–º–µ–Ω—Ç (Structured Document Tag) - XML —ç–ª–µ–º–µ–Ω—Ç
    result = _replace_in_sdt(element, original_value, replacement_value)
    
elif hasattr(element, 'rows'):
    # –¢–∞–±–ª–∏—Ü–∞
    result = _replace_in_table(element, original_value, replacement_value, position)
    
elif hasattr(element, 'text'):
    # –ü–∞—Ä–∞–≥—Ä–∞—Ñ
    result = _replace_in_paragraph(element, original_value, replacement_value, position)
```

---

### **4.5. –ó–∞–º–µ–Ω–∞ –≤ –ü–ê–†–ê–ì–†–ê–§–ï**

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç:** `FormatterApplier._replace_in_paragraph()`

**–ü—Ä–æ–±–ª–µ–º–∞:** –¢–µ–∫—Å—Ç –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞–∑–±–∏—Ç –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ **runs** (—Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Å —Ä–∞–∑–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º).

**–ü—Ä–∏–º–µ—Ä:**
```python
–ü–∞—Ä–∞–≥—Ä–∞—Ñ: "–ú–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ä–∞–∑–≤–∏—Ç–∏—è"
Run 0:    "–ú–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ "       (–∂–∏—Ä–Ω—ã–π)
Run 1:    "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ "    (–æ–±—ã—á–Ω—ã–π)
Run 2:    "—Ä–∞–∑–≤–∏—Ç–∏—è"            (–∫—É—Ä—Å–∏–≤)
```

**–ê–ª–≥–æ—Ä–∏—Ç–º –∑–∞–º–µ–Ω—ã:**

**–®–∞–≥ 1: –ü–æ–∏—Å–∫ –≤ –æ–¥–Ω–æ–º run**
```python
for i, run in enumerate(paragraph.runs):
    run_text = run.text or ''
    
    # –ü—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    if original_value in run_text:
        run.text = run_text.replace(original_value, replacement_value, 1)
        run.font.highlight_color = WD_COLOR_INDEX.YELLOW  # –í—ã–¥–µ–ª–µ–Ω–∏–µ
        return True
```

**–®–∞–≥ 2: –ü–æ–∏—Å–∫ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö runs**
```python
# –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ –≤—Å–µ—Ö runs
full_text = ''.join(run.text for run in paragraph.runs)

if original_value in full_text:
    start_pos = full_text.find(original_value)
    end_pos = start_pos + len(original_value)
    
    # –ù–∞—Ö–æ–¥–∏–º –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ runs –∏ –∑–∞–º–µ–Ω—è–µ–º
    return _replace_across_runs(paragraph, original_value, replacement_value, start_pos, end_pos)
```

**–®–∞–≥ 3: –ó–∞–º–µ–Ω–∞ —á–µ—Ä–µ–∑ runs (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)**
```python
# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ runs –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã
affected_runs = []
current_pos = 0

for i, run in enumerate(paragraph.runs):
    run_start = current_pos
    run_end = current_pos + len(run.text)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ
    if not (run_end <= start_pos or run_start >= end_pos):
        affected_runs.append({
            'index': i,
            'run': run,
            'text_start': max(0, start_pos - run_start),
            'text_end': min(len(run.text), end_pos - run_start)
        })
    
    current_pos = run_end

# –ó–∞–º–µ–Ω—è–µ–º –≤ –ø–µ—Ä–≤–æ–º run, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –æ–±—Ä–µ–∑–∞–µ–º
for i, run_info in enumerate(affected_runs):
    if i == 0:
        # –ü–µ—Ä–≤—ã–π run - –≤—Å—Ç–∞–≤–ª—è–µ–º replacement_value
        run.text = run.text[:text_start] + replacement_value + run.text[text_end:]
        run.font.highlight_color = WD_COLOR_INDEX.YELLOW
    else:
        # –û—Å—Ç–∞–ª—å–Ω—ã–µ runs - —É–¥–∞–ª—è–µ–º –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã–π —Ç–µ–∫—Å—Ç
        run.text = run.text[:text_start] + run.text[text_end:]
```

---

### **4.6. –ó–∞–º–µ–Ω–∞ –≤ –¢–ê–ë–õ–ò–¶–ï**

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç:** `FormatterApplier._replace_in_table()`

**–ê–ª–≥–æ—Ä–∏—Ç–º:**

**–®–∞–≥ 1: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–∞—Ä—Ç—ã –ø–æ–∑–∏—Ü–∏–π —è—á–µ–µ–∫**
```python
table_text = ""
cell_positions = []

for row_idx, row in enumerate(table.rows):
    for cell_idx, cell in enumerate(row.cells):
        cell_text = cell.text or ''
        cell_start = len(table_text)
        table_text += cell_text
        cell_end = len(table_text)
        
        cell_positions.append({
            'row': row_idx,
            'col': cell_idx,
            'start': cell_start,
            'end': cell_end,
            'cell': cell,
            'text': cell_text
        })
        
        # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –º–µ–∂–¥—É —è—á–µ–π–∫–∞–º–∏ (–∫–∞–∫ –≤ BlockBuilder)
        if cell_idx < len(row.cells) - 1:
            table_text += " | "
    
    table_text += "\n"  # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
```

**–ü—Ä–∏–º–µ—Ä:**
```
–¢–∞–±–ª–∏—Ü–∞:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –Ø—á–µ–π–∫–∞ A ‚îÇ –Ø—á–µ–π–∫–∞ B ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ –Ø—á–µ–π–∫–∞ C ‚îÇ –Ø—á–µ–π–∫–∞ D ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

table_text = "–Ø—á–µ–π–∫–∞ A | –Ø—á–µ–π–∫–∞ B\n–Ø—á–µ–π–∫–∞ C | –Ø—á–µ–π–∫–∞ D\n"

cell_positions = [
    {row: 0, col: 0, start: 0, end: 8, text: "–Ø—á–µ–π–∫–∞ A"},
    {row: 0, col: 1, start: 11, end: 19, text: "–Ø—á–µ–π–∫–∞ B"},
    {row: 1, col: 0, start: 20, end: 28, text: "–Ø—á–µ–π–∫–∞ C"},
    {row: 1, col: 1, start: 31, end: 39, text: "–Ø—á–µ–π–∫–∞ D"}
]
```

**–®–∞–≥ 2: –ü–æ–∏—Å–∫ —è—á–µ–π–∫–∏ –ø–æ –ø–æ–∑–∏—Ü–∏–∏**
```python
target_position = position_info.get('start')  # –ü–æ–∑–∏—Ü–∏—è –∏–∑ –¥–µ—Ç–µ–∫—Ü–∏–∏

for cell_info in cell_positions:
    if original_value in cell_info['text']:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–∑–∏—Ü–∏–∏
        if target_position is None or (cell_info['start'] <= target_position < cell_info['end']):
            target_cell = cell_info
            break
```

**–®–∞–≥ 3: –ó–∞–º–µ–Ω–∞ –≤ –Ω–∞–π–¥–µ–Ω–Ω–æ–π —è—á–µ–π–∫–µ**
```python
cell = target_cell['cell']

for paragraph in cell.paragraphs:
    if original_value in paragraph.text:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –∑–∞–º–µ–Ω—ã –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ
        self._replace_in_paragraph(paragraph, original_value, replacement_value, {})
        return True
```

---

### **4.7. –ó–∞–º–µ–Ω–∞ –≤ SDT (Structured Document Tag)**

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç:** `FormatterApplier._apply_single_replacement()` (SDT –±–ª–æ–∫)

**–ß—Ç–æ —Ç–∞–∫–æ–µ SDT:** XML —ç–ª–µ–º–µ–Ω—Ç—ã –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö/–ø–æ–¥–≤–∞–ª–∞—Ö DOCX

**–ê–ª–≥–æ—Ä–∏—Ç–º:**
```python
# –ò—Å–ø–æ–ª—å–∑—É–µ–º XPath –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
text_elements = element.xpath(
    './/w:t',
    namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}
)

for text_element in text_elements:
    current_text = text_element.text or ''
    
    if original_value in current_text:
        # –ü—Ä—è–º–∞—è –∑–∞–º–µ–Ω–∞ —Ç–µ–∫—Å—Ç–∞ –≤ XML —ç–ª–µ–º–µ–Ω—Ç–µ
        new_text = current_text.replace(original_value, replacement_value, 1)
        text_element.text = new_text
        return True
```

**–ü—Ä–∏–º–µ—Ä SDT:**
```xml
<w:sdt>
    <w:p>
        <w:r>
            <w:t>–ï–ò–°–£–§–•–î.13/–û–ö-2023</w:t>
        </w:r>
    </w:p>
</w:sdt>

–ü–æ—Å–ª–µ –∑–∞–º–µ–Ω—ã:
<w:t>9112b0d5-9237-56e3-a2df-210912cecc09.13/–û–ö-2023</w:t>
```

---

### **4.8. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ –ø–æ–¥–≤–∞–ª–æ–≤**

```python
# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ –æ—Å–Ω–æ–≤–Ω–æ–π –∑–∞–º–µ–Ω—ã
header_footer_stats = self._apply_replacements_to_headers_footers(doc, normalized_replacements)

# –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —Å–µ–∫—Ü–∏—è–º –¥–æ–∫—É–º–µ–Ω—Ç–∞
for section in doc.sections:
    # –ó–∞–≥–æ–ª–æ–≤–∫–∏
    for paragraph in section.header.paragraphs:
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–µ –∂–µ –∑–∞–º–µ–Ω—ã
        
    # –ü–æ–¥–≤–∞–ª—ã
    for paragraph in section.footer.paragraphs:
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–µ –∂–µ –∑–∞–º–µ–Ω—ã
```

---

## üéØ –≠–¢–ê–ü 5: –°–û–•–†–ê–ù–ï–ù–ò–ï –î–û–ö–£–ú–ï–ù–¢–ê

```python
doc.save(output_path)
```

**–ß—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è:**
- –í—Å–µ –∑–∞–º–µ–Ω—ã –ø—Ä–∏–º–µ–Ω–µ–Ω—ã
- –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ
- UUID –≤—ã–¥–µ–ª–µ–Ω—ã –∂—ë–ª—Ç—ã–º —Ü–≤–µ—Ç–æ–º (–µ—Å–ª–∏ `highlight_replacements=True`)
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–µ –∏–∑–º–µ–Ω–µ–Ω–∞

---

## üéØ –≠–¢–ê–ü 6: –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–ß–Å–¢–û–í

### **6.1. Excel –æ—Ç—á—ë—Ç**

**–ú–µ—Ç–æ–¥:** `FullAnonymizer._generate_excel_report()`

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ Excel:**
```
| ‚Ññ | –ò—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ | UUID –∑–∞–º–µ–Ω—ã | –ö–∞—Ç–µ–≥–æ—Ä–∏—è | –ú–µ—Ç–æ–¥ | Confidence |
|---|-------------------|-------------|-----------|-------|------------|
| 1 | –ï–ò–°–£–§–•–î | 9112b0d5-... | information_system | complex_abbreviation | 1.0 |
| 2 | –ö. –°. –ú—è—Å–Ω–∏–∫–æ–≤ | 871f90b0-... | person_name | custom_matcher | 0.9 |
| 3 | –ú–ò–ù–ò–°–¢–ï–†–°–¢–í–û... | 5b407955-... | organization | regex | 1.0 |
```

**–ì–µ–Ω–µ—Ä–∞—Ü–∏—è UUID –¥–ª—è –æ—Ç—á—ë—Ç–∞:**
```python
for match in all_matches:
    original_value = match['original_value']
    category = match['category']
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º UUID —á–µ—Ä–µ–∑ UUIDMapper (–¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Å—Ç–∏—á–µ—Å–∫–∏)
    uuid = self.formatter.uuid_mapper.get_uuid_for_text(original_value, category)
    
    worksheet.append([
        index,
        original_value,
        uuid,
        category,
        match.get('method', 'N/A'),
        match.get('confidence', 'N/A')
    ])
```

---

### **6.2. JSON –∂—É—Ä–Ω–∞–ª**

**–ú–µ—Ç–æ–¥:** `FullAnonymizer._generate_json_ledger()`

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ JSON:**
```json
{
  "ledger_version": "1.0",
  "timestamp": "2025-12-03T16:33:40",
  "statistics": {
    "total_replacements": 29,
    "categories": {
      "person_name": 3,
      "organization": 2,
      "information_system": 12,
      "contract_number": 5,
      "inn": 2,
      "email": 1
    }
  },
  "replacements": [
    {
      "original_value": "–ú–ò–ù–ò–°–¢–ï–†–°–¢–í–û –ò–ù–§–û–†–ú–ê–¶–ò–û–ù–ù–û–ì–û –†–ê–ó–í–ò–¢–ò–Ø –ò –°–í–Ø–ó–ò",
      "uuid": "5b407955-d6e1-59ab-a5f5-50f38ec7291b",
      "category": "organization",
      "method": "regex",
      "confidence": 1.0,
      "source": "nlp_service"
    }
  ]
}
```

---

## üéØ –≠–¢–ê–ü 7: –í–û–ó–í–†–ê–¢ –†–ï–ó–£–õ–¨–¢–ê–¢–ê

```python
# –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –≤ Base64
with open(output_path, 'rb') as f:
    anonymized_doc_base64 = base64.b64encode(f.read()).decode('utf-8')

with open(excel_path, 'rb') as f:
    excel_report_base64 = base64.b64encode(f.read()).decode('utf-8')

# –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
return JSONResponse({
    "status": "success",
    "statistics": {
        "total_replacements": 29,
        "categories": {...}
    },
    "files_base64": {
        "anonymized_document_base64": anonymized_doc_base64,
        "excel_report_base64": excel_report_base64,
        "json_ledger_base64": json_ledger_base64
    }
})
```

---

## üìä –§–û–†–ú–ê–¢ –î–ê–ù–ù–´–• –ú–ï–ñ–î–£ –ö–û–ú–ü–û–ù–ï–ù–¢–ê–ú–ò

### **1. Block Builder ‚Üí Rule Engine / NLP Service**
```python
{
    "block_id": str,
    "text": str,
    "element": object,
    "type": str
}
```

### **2. NLP Service ‚Üí Full Anonymizer**
```python
{
    "category": str,
    "original_value": str,
    "confidence": float,
    "position": {"start": int, "end": int},
    "method": str,
    "block_id": str
}
```

### **3. Rule Engine ‚Üí Full Anonymizer**
```python
{
    "category": str,
    "original_value": str,
    "position": {"start": int, "end": int},
    "confidence": float,
    "source": "regex"
}
```

### **4. Full Anonymizer ‚Üí Formatter Applier**
```python
{
    "block_id": str,
    "original_value": str,
    "uuid": str,  # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Å—Ç–∏—á–µ—Å–∫–∏–π UUID
    "position": {"start": int, "end": int},
    "element": object,  # –°—Å—ã–ª–∫–∞ –Ω–∞ DOCX —ç–ª–µ–º–µ–Ω—Ç
    "category": str,
    "confidence": float,
    "source": str,
    "method": str
}
```

---

## üîë –ö–õ–Æ–ß–ï–í–´–ï –û–°–û–ë–ï–ù–ù–û–°–¢–ò –ü–†–û–¶–ï–°–°–ê

### ‚úÖ **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:**

1. **–ü–æ–±–ª–æ—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞** ‚Äî –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –¥–µ—Ç–µ–∫—Ü–∏–∏ –≤—Å–µ–≥–¥–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –º–∞–ø—è—Ç—Å—è –Ω–∞ —ç–ª–µ–º–µ–Ω—Ç—ã
2. **–î–µ—Ç–µ—Ä–º–∏–Ω–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ UUID** ‚Äî –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤—Å–µ–≥–¥–∞ –ø–æ–ª—É—á–∞—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ UUID
3. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è** ‚Äî –∑–∞–º–µ–Ω—ã –ø—Ä–æ–∏—Å—Ö–æ–¥—è—Ç –Ω–∞ —É—Ä–æ–≤–Ω–µ runs, —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ —Ç–µ—Ä—è–µ—Ç—Å—è
4. **–î–≤–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–π** ‚Äî NLP Service + Rule Engine –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å
5. **–í—ã–¥–µ–ª–µ–Ω–∏–µ UUID** ‚Äî –∂—ë–ª—Ç—ã–π —Ñ–æ–Ω –ø–æ–º–æ–≥–∞–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–∞–º–µ–Ω—ã
6. **–î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è** ‚Äî –ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏–µ—Å—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –Ω–µ –¥—É–±–ª–∏—Ä—É—é—Ç—Å—è

### ‚ö†Ô∏è **–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:**

1. **–ù–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –º–Ω–æ–≥–æ–±–ª–æ—á–Ω—ã–µ –¥–µ—Ç–µ–∫—Ü–∏–∏** ‚Äî –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –±–ª–æ–∫–∞–º, –æ–Ω –Ω–µ –±—É–¥–µ—Ç –∑–∞–º–µ–Ω—ë–Ω —Ü–µ–ª–∏–∫–æ–º
2. **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç NLP Service** ‚Äî –µ—Å–ª–∏ NLP Service –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –¥–µ—Ç–µ–∫—Ü–∏–∏ –±—É–¥—É—Ç —Ç–æ–ª—å–∫–æ –æ—Ç Rule Engine
3. **–ü–æ–∑–∏—Ü–∏–æ–Ω–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å** ‚Äî –µ—Å–ª–∏ –ø–æ–∑–∏—Ü–∏–∏ –Ω–µ—Ç–æ—á–Ω—ã–µ, –∑–∞–º–µ–Ω–∞ –º–æ–∂–µ—Ç –Ω–µ —Å—Ä–∞–±–æ—Ç–∞—Ç—å

---

## üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–ò–ú–ï–†–ê –í–´–ü–û–õ–ù–ï–ù–ò–Ø

**–í—Ö–æ–¥–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç:** `test_01_1_4_SD33.docx`

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**
- **–ë–ª–æ–∫–æ–≤ –∏–∑–≤–ª–µ—á–µ–Ω–æ:** ~50
- **–î–µ—Ç–µ–∫—Ü–∏–π NLP Service:** 21
- **–î–µ—Ç–µ–∫—Ü–∏–π Rule Engine:** 3
- **–ò—Ç–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–µ—Ç–µ–∫—Ü–∏–π:** 24
- **–í—ã–ø–æ–ª–Ω–µ–Ω–æ –∑–∞–º–µ–Ω:** 29 (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑)
- **–ö–∞—Ç–µ–≥–æ—Ä–∏–∏:**
  - person_name: 3
  - organization: 2
  - information_system: 12
  - contract_number: 5
  - inn: 2
  - email: 1

**–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:** ~5-10 —Å–µ–∫—É–Ω–¥

---

## üéì –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï

–ü—Ä–æ—Ü–µ—Å—Å –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏–∏ ‚Äî —ç—Ç–æ **–º–Ω–æ–≥–æ—Å—Ç—É–ø–µ–Ω—á–∞—Ç—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä**, –≥–¥–µ –∫–∞–∂–¥—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫—É—é –∑–∞–¥–∞—á—É:

1. **BlockBuilder** ‚Äî —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç
2. **RuleAdapter** ‚Äî –ø—Ä–∏–º–µ–Ω—è–µ—Ç regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã
3. **NLP Service** ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç AI –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
4. **FullAnonymizer** ‚Äî –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –≤–µ—Å—å –ø—Ä–æ—Ü–µ—Å—Å
5. **FormatterApplier** ‚Äî –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–º–µ–Ω—ã —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
6. **UUIDMapper** ‚Äî –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ UUID

–í—Å—è —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç **—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ**, —á—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.
