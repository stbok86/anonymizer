"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∑–∞–º–µ–Ω –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
"""

import re
import uuid
from typing import List, Dict, Any, Optional, Tuple
from docx.shared import RGBColor
from docx.enum.text import WD_COLOR_INDEX

try:
    from uuid_mapper import UUIDMapper
except ImportError:
    import sys
    import os
    sys.path.append(os.path.dirname(__file__))
    from uuid_mapper import UUIDMapper

try:
    from docx_metadata_handler import DocxMetadataHandler
except ImportError:
    import sys
    import os
    sys.path.append(os.path.dirname(__file__))
    from docx_metadata_handler import DocxMetadataHandler


class FormatterApplier:
    def __init__(self, highlight_replacements: bool = True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–º–µ–Ω–∏—Ç–µ–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        
        Args:
            highlight_replacements: –í—ã–¥–µ–ª—è—Ç—å –ª–∏ –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∂—ë–ª—Ç—ã–º —Ü–≤–µ—Ç–æ–º (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True)
        """
        self.highlight_replacements = highlight_replacements
        self.replacement_color = WD_COLOR_INDEX.YELLOW  # –ñ—ë–ª—Ç—ã–π —Ü–≤–µ—Ç –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è UUID
        
        # üéØ –¶–ï–ù–¢–†–ê–õ–ò–ó–û–í–ê–ù–ù–´–ô UUID MAPPER
        self.uuid_mapper = UUIDMapper(namespace="document-anonymization")
        
    def apply_replacements(self, doc, replacements_table: List[Dict]) -> int:
        """
        –ú–µ—Ç–æ–¥-–∞–ª–∏–∞—Å –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ –≤–µ—Ä—Å–∏—è–º–∏
        
        Args:
            doc: –î–æ–∫—É–º–µ–Ω—Ç DOCX
            replacements_table: –¢–∞–±–ª–∏—Ü–∞ –∑–∞–º–µ–Ω
            
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–µ–Ω–Ω—ã—Ö –∑–∞–º–µ–Ω
        """
        result = self.apply_replacements_to_document(doc, replacements_table)
        return result.get('total_replacements', 0)
    
    def apply_replacements_to_document(self, doc, replacements: List[Dict]) -> Dict[str, Any]:
        """
        –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∑–∞–º–µ–Ω –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        
        Args:
            doc: –î–æ–∫—É–º–µ–Ω—Ç DOCX 
            replacements: –°–ø–∏—Å–æ–∫ –∑–∞–º–µ–Ω —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–æ–∑–∏—Ü–∏—è—Ö
            
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∑–∞–º–µ–Ω
        """
        print(f"üìù [FORMATTER_APPLIER] –ü–æ–ª—É—á–µ–Ω–æ –∑–∞–º–µ–Ω –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(replacements)}")
        
        # üéØ –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –ó–ê–ú–ï–ù: –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–µ UUID
        normalized_replacements = self._normalize_replacements_with_centralized_uuids(replacements)
        
        for i, match in enumerate(normalized_replacements[:5]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
            print(f"üìù [FORMATTER_APPLIER] –ó–∞–º–µ–Ω–∞ {i+1}: '{match.get('original_value', 'N/A')}' ‚Üí '{match.get('uuid', 'N/A')}'")
        if len(normalized_replacements) > 5:
            print(f"üìù [FORMATTER_APPLIER] ... –∏ –µ—â–µ {len(replacements) - 5} –∑–∞–º–µ–Ω")
            
        if not replacements:
            return {
                'total_replacements': 0,
                'categories': {},
                'blocks_processed': 0
            }
        
        stats = {
            'total_replacements': 0,
            'categories': {},
            'blocks_processed': 0,
            'replacement_details': []
        }
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∑–∞–º–µ–Ω—ã –ø–æ –±–ª–æ–∫–∞–º –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        replacements_by_block = {}
        for replacement in normalized_replacements:  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Å UUID
            block_id = replacement.get('block_id')
            if block_id not in replacements_by_block:
                replacements_by_block[block_id] = []
            replacements_by_block[block_id].append(replacement)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –±–ª–æ–∫
        for block_id, block_replacements in replacements_by_block.items():
            try:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∑–∞–º–µ–Ω—ã –ø–æ –ø–æ–∑–∏—Ü–∏–∏ (–≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∑–∞–º–µ–Ω—ã)
                block_replacements.sort(key=lambda x: x.get('position', {}).get('start', 0), reverse=True)
                
                block_stats = self._apply_replacements_to_block(block_replacements)
                
                # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                stats['total_replacements'] += block_stats['replacements_made']
                stats['blocks_processed'] += 1
                
                # –ü–æ–¥—Å—á–µ—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                for replacement in block_replacements:
                    category = replacement.get('category', 'unknown')
                    if category not in stats['categories']:
                        stats['categories'][category] = 0
                    stats['categories'][category] += 1
                
                stats['replacement_details'].extend(block_stats['details'])
                
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–ª–æ–∫–∞ {block_id}: {str(e)}")
                continue
        
        # üéØ –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê: Headers & Footers –ü–û–°–õ–ï –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        print(f"üìù [FORMATTER_APPLIER] –ù–∞—á–∏–Ω–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–æ–≤...")
        header_footer_stats = self._apply_replacements_to_headers_footers(doc, normalized_replacements)
        
        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É headers/footers
        stats['total_replacements'] += header_footer_stats['total_replacements']
        stats['headers_footers_processed'] = header_footer_stats['headers_footers_processed']
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        for category, count in header_footer_stats['categories'].items():
            if category not in stats['categories']:
                stats['categories'][category] = 0
            stats['categories'][category] += count
        
        stats['replacement_details'].extend(header_footer_stats['replacement_details'])
        
        print(f"üìù [FORMATTER_APPLIER] –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ó–∞–º–µ–Ω –≤ headers/footers: {header_footer_stats['total_replacements']}")
        
        # üéØ –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê: Headers & Footers –ü–û–°–õ–ï –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        print(f"üìù [FORMATTER_APPLIER] –ù–∞—á–∏–Ω–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–æ–≤...")
        header_footer_stats = self._apply_replacements_to_headers_footers(doc, normalized_replacements)
        
        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É headers/footers
        stats['total_replacements'] += header_footer_stats['total_replacements']
        stats['headers_footers_processed'] = header_footer_stats['headers_footers_processed']
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        for category, count in header_footer_stats['categories'].items():
            if category not in stats['categories']:
                stats['categories'][category] = 0
            stats['categories'][category] += count
        
        stats['replacement_details'].extend(header_footer_stats['replacement_details'])
        
        print(f"üìù [FORMATTER_APPLIER] –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ó–∞–º–µ–Ω –≤ headers/footers: {header_footer_stats['total_replacements']}")
        
        # üéØ –í–ê–ñ–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–º–µ–Ω—ã –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –æ—Ç—á–µ—Ç–∞—Ö
        # –£–±–∏—Ä–∞–µ–º element –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        serializable_normalized = []
        for r in normalized_replacements:
            r_copy = r.copy()
            r_copy.pop('element', None)  # –£–¥–∞–ª—è–µ–º XML —ç–ª–µ–º–µ–Ω—Ç
            serializable_normalized.append(r_copy)
        
        stats['normalized_replacements'] = serializable_normalized
        
        return stats
    
    def _apply_replacements_to_block(self, block_replacements: List[Dict]) -> Dict[str, Any]:
        """
        –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∑–∞–º–µ–Ω –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –±–ª–æ–∫—É
        
        Args:
            block_replacements: –°–ø–∏—Å–æ–∫ –∑–∞–º–µ–Ω –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –±–ª–æ–∫–∞
            
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –±–ª–æ–∫—É
        """
        block_stats = {
            'replacements_made': 0,
            'details': []
        }
        
        for replacement in block_replacements:
            try:
                success = self._apply_single_replacement(replacement)
                if success:
                    block_stats['replacements_made'] += 1
                    block_stats['details'].append({
                        'uuid': replacement.get('uuid'),
                        'category': replacement.get('category'),
                        'original_value': replacement.get('original_value'),
                        'success': True
                    })
                    
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –∑–∞–º–µ–Ω—ã {replacement.get('uuid', 'unknown')}: {str(e)}")
                block_stats['details'].append({
                    'uuid': replacement.get('uuid'),
                    'category': replacement.get('category'),
                    'original_value': replacement.get('original_value'),
                    'success': False,
                    'error': str(e)
                })
        
        return block_stats
    
    def _apply_single_replacement(self, replacement: Dict) -> bool:
        """
        –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–¥–Ω–æ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–º–µ–Ω—ã
        
        Args:
            replacement: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–º–µ–Ω–µ
            
        Returns:
            True –µ—Å–ª–∏ –∑–∞–º–µ–Ω–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            element = replacement.get('element')
            original_value = replacement.get('original_value', '')
            position = replacement.get('position', {})
            
            print(f"\nüîß [SINGLE_REPLACEMENT] –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–º–µ–Ω—É:")
            print(f"üîß [SINGLE_REPLACEMENT] –û—Ä–∏–≥–∏–Ω–∞–ª: '{original_value}'")
            print(f"üîß [SINGLE_REPLACEMENT] Element type: {type(element) if element else 'None'}")
            print(f"üîß [SINGLE_REPLACEMENT] Position: {position}")
            print(f"üîß [SINGLE_REPLACEMENT] Block ID: {replacement.get('block_id', 'N/A')}")
            print(f"üîß [SINGLE_REPLACEMENT] Category: {replacement.get('category', 'N/A')}")
            
            if element is None:
                print(f"üîß [SINGLE_REPLACEMENT] ‚ùå Element is None")
                return False
                
            if not original_value:
                print(f"üîß [SINGLE_REPLACEMENT] ‚ùå original_value is empty")
                return False
                
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è None –∑–Ω–∞—á–µ–Ω–∏–π
            if original_value is None:
                print(f"üîß [SINGLE_REPLACEMENT] ‚ùå original_value is None")
                return False
            
            # üéØ –¶–ï–ù–¢–†–ê–õ–ò–ó–û–í–ê–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è UUID (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º placeholder)
            existing_uuid = replacement.get('uuid', '')
            if not existing_uuid or existing_uuid == 'placeholder':
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Å—Ç–∏—á–µ—Å–∫–∏–π UUID
                replacement_value = self._generate_replacement_value(
                    original_value, 
                    replacement.get('category', 'unknown')
                )
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –≥–æ—Ç–æ–≤—ã–π UUID (–µ—Å–ª–∏ –æ–Ω —Ä–µ–∞–ª—å–Ω—ã–π)
                replacement_value = existing_uuid
            
            print(f"üîß [SINGLE_REPLACEMENT] UUID –∑–∞–º–µ–Ω—ã: '{replacement_value}'")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–∞ –ø–µ—Ä–µ–¥ –∑–∞–º–µ–Ω–æ–π
            if hasattr(element, 'text'):
                current_text = getattr(element, 'text', '') or ''
                print(f"üîß [SINGLE_REPLACEMENT] –¢–µ–∫—É—â–∏–π text: '{current_text}'")
            
            if hasattr(element, 'rows'):
                print(f"üîß [SINGLE_REPLACEMENT] –¢–∞–±–ª–∏—Ü–∞ —Å {len(element.rows)} —Å—Ç—Ä–æ–∫–∞–º–∏")
            

            # --- SDT (lxml.etree._Element) ---
            try:
                import lxml.etree
            except ImportError:
                lxml = None
            if 'lxml' in str(type(element)) or (hasattr(element, 'tag') and hasattr(element, 'xpath')):
                # SDT-—ç–ª–µ–º–µ–Ω—Ç: –∏—â–µ–º w:t –∏ –∑–∞–º–µ–Ω—è–µ–º —Ç–µ–∫—Å—Ç
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º xpath –±–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ namespaces –¥–ª—è BaseOxmlElement
                    # –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∏–º–µ–Ω —É–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä—è–º–æ –≤ XPath —Å—Ç—Ä–æ–∫–µ
                    try:
                        # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å xpath —Å namespaces (–¥–ª—è lxml.etree._Element)
                        text_elements = element.xpath('.//w:t', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'})
                    except TypeError:
                        # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º xpath –±–µ–∑ namespaces (–¥–ª—è BaseOxmlElement)
                        # BaseOxmlElement —É–∂–µ –∑–Ω–∞–µ—Ç –æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞—Ö –∏–º–µ–Ω –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                        text_elements = element.xpath('.//w:t')
                    
                    replaced = False
                    for text_element in text_elements:
                        current_text = text_element.text or ''
                        if original_value and original_value in current_text:
                            new_text = current_text.replace(original_value, replacement_value, 1)
                            text_element.text = new_text
                            print(f"üîß [SINGLE_REPLACEMENT][SDT] ‚úÖ –ó–∞–º–µ–Ω–∞ –≤ SDT: '{current_text}' ‚Üí '{new_text}'")
                            replaced = True
                            break  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ
                    if replaced:
                        return True
                    else:
                        print(f"üîß [SINGLE_REPLACEMENT][SDT] ‚ùå –ó–Ω–∞—á–µ–Ω–∏–µ '{original_value}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ SDT")
                        return False
                except Exception as e:
                    print(f"üîß [SINGLE_REPLACEMENT][SDT] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–º–µ–Ω–µ –≤ SDT: {str(e)}")
                    return False

            # --- –¢–∞–±–ª–∏—Ü–∞ ---
            if hasattr(element, 'rows'):
                print(f"üîß [SINGLE_REPLACEMENT] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É")
                result = self._replace_in_table(element, original_value, replacement_value, position)
                print(f"üîß [SINGLE_REPLACEMENT] –†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–º–µ–Ω—ã –≤ —Ç–∞–±–ª–∏—Ü–µ: {result}")
                return result
            # --- –ü–∞—Ä–∞–≥—Ä–∞—Ñ ---
            elif hasattr(element, 'text'):
                print(f"üîß [SINGLE_REPLACEMENT] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ")
                result = self._replace_in_paragraph(element, original_value, replacement_value, position)
                print(f"üîß [SINGLE_REPLACEMENT] –†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–º–µ–Ω—ã –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ: {result}")
                return result
            # --- –û–±—â–∏–π —Å–ª—É—á–∞–π ---
            else:
                print(f"üîß [SINGLE_REPLACEMENT] –û–±—â–∏–π —Å–ª—É—á–∞–π –∑–∞–º–µ–Ω—ã")
                current_text = getattr(element, 'text', '')
                if current_text is None:
                    current_text = ''
                print(f"üîß [SINGLE_REPLACEMENT] –¢–µ–∫—É—â–∏–π —Ç–µ–∫—Å—Ç —ç–ª–µ–º–µ–Ω—Ç–∞: '{current_text}'")
                if original_value and original_value in current_text:
                    new_text = current_text.replace(original_value, replacement_value)
                    element.text = new_text
                    print(f"üîß [SINGLE_REPLACEMENT] ‚úÖ –û–±—â–∞—è –∑–∞–º–µ–Ω–∞: '{current_text}' ‚Üí '{new_text}'")
                    return True
                else:
                    print(f"üîß [SINGLE_REPLACEMENT] ‚ùå –ó–Ω–∞—á–µ–Ω–∏–µ '{original_value}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ç–µ–∫—Å—Ç–µ '{current_text}'")
                print(f"üîß [SINGLE_REPLACEMENT] ‚ùå –ó–∞–º–µ–Ω–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
                return False
            
        except Exception as e:
            print(f"üîß [SINGLE_REPLACEMENT] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –∑–∞–º–µ–Ω—ã: {str(e)}")
            import traceback
            print(f"üîß [SINGLE_REPLACEMENT] Traceback: {traceback.format_exc()}")
            return False
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –∑–∞–º–µ–Ω—ã: {str(e)}")
            return False
    
    def _normalize_text(self, text: str) -> str:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç, –∑–∞–º–µ–Ω—è—è —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã –ø—Ä–æ–±–µ–ª–æ–≤ –Ω–∞ –æ–±—ã—á–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
        –∏ —É–¥–∞–ª—è—è –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        """
        if not text:
            return ''
        
        # –ó–∞–º–µ–Ω—è–µ–º –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã (160) –∏ –¥—Ä—É–≥–∏–µ –≤–∏–¥—ã –ø—Ä–æ–±–µ–ª–æ–≤ –Ω–∞ –æ–±—ã—á–Ω—ã–π –ø—Ä–æ–±–µ–ª (32)
        text = text.replace('\u00A0', ' ')  # –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–π –ø—Ä–æ–±–µ–ª
        text = text.replace('\u2009', ' ')  # —Ç–æ–Ω–∫–∏–π –ø—Ä–æ–±–µ–ª
        text = text.replace('\u2007', ' ')  # —Ü–∏—Ñ—Ä–æ–≤–æ–π –ø—Ä–æ–±–µ–ª
        text = text.replace('\u2008', ' ')  # –ø—É–Ω–∫—Ç—É–∞—Ü–∏–æ–Ω–Ω—ã–π –ø—Ä–æ–±–µ–ª
        text = text.replace('\u202F', ' ')  # —É–∑–∫–∏–π –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–π –ø—Ä–æ–±–µ–ª
        text = text.replace('\u3000', ' ')  # –∏–¥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–±–µ–ª
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
        return ' '.join(text.split())

    def _replace_in_paragraph(self, paragraph, original_value: str, replacement_value: str, position: Dict) -> bool:
        """
        –ó–∞–º–µ–Ω–∞ —Ç–µ–∫—Å—Ç–∞ –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —É—á–µ—Ç–æ–º –ø–æ–∑–∏—Ü–∏–∏
        
        Args:
            paragraph: –ü–∞—Ä–∞–≥—Ä–∞—Ñ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            original_value: –ò—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –∑–∞–º–µ–Ω—ã
            replacement_value: –ó–∞–º–µ—â–∞—é—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            position: –ü–æ–∑–∏—Ü–∏—è –∑–∞–º–µ–Ω—ã –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–ø–∞–¥–∞–Ω–∏—è
            
        Returns:
            True –µ—Å–ª–∏ –∑–∞–º–µ–Ω–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∞
        """
        try:
            # print(f"üîß [PARAGRAPH] –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–º–µ–Ω—ã: '{original_value}' ‚Üí '{replacement_value}'")
            # print(f"üîß [PARAGRAPH] –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–∑–∏—Ü–∏–∏: {position}")
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            paragraph_text = getattr(paragraph, 'text', '') or ''
            # print(f"üîß [PARAGRAPH] –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞: '{paragraph_text}'")
            # print(f"üîß [PARAGRAPH] –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ runs: {len(paragraph.runs)}")
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞
            original_value_normalized = self._normalize_text(original_value)
            paragraph_text_normalized = self._normalize_text(paragraph_text)
            # print(f"üîß [PARAGRAPH] –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∏—Å–∫–æ–º—ã–π —Ç–µ–∫—Å—Ç: '{original_value_normalized}'")
            # print(f"üîß [PARAGRAPH] –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞: '{paragraph_text_normalized}'")
            if not original_value_normalized or original_value_normalized not in paragraph_text_normalized:
                # print(f"üîß [PARAGRAPH] ‚ùå –¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏")
                return False
            # –ü–æ–ª—É—á–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–æ–∑–∏—Ü–∏—é –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            target_position = position.get('start') if position else None
            # print(f"üîß [PARAGRAPH] –¶–µ–ª–µ–≤–∞—è –ø–æ–∑–∏—Ü–∏—è: {target_position}")
            # –ï—Å–ª–∏ –ø–æ–∑–∏—Ü–∏—è —É–∫–∞–∑–∞–Ω–∞, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
            if target_position is not None:
                # –ò—â–µ–º –ø–æ–∑–∏—Ü–∏—é —Ç–µ–∫—Å—Ç–∞ –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ
                text_position_in_paragraph = paragraph_text_normalized.find(original_value_normalized)
                if text_position_in_paragraph == -1:
                    # print(f"üîß [PARAGRAPH] ‚ùå –¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ")
                    return False
                # print(f"üîß [PARAGRAPH] –ü–æ–∑–∏—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ: {text_position_in_paragraph}")
                # print(f"üîß [PARAGRAPH] –¶–µ–ª–µ–≤–∞—è –ø–æ–∑–∏—Ü–∏—è –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ: {target_position}")
                # –î–ª—è –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω–µ–µ —Å—Ç—Ä–æ–≥—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –ø–æ–∑–∏—Ü–∏–∏
                # —Ç–∞–∫ –∫–∞–∫ –ø–æ–∑–∏—Ü–∏—è –º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –∏–∑-–∑–∞ —Ä–∞–∑–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞
                position_match = True  # –î–ª—è –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ –ø–æ–∫–∞ –ø—Ä–∏–Ω–∏–º–∞–µ–º –ª—é–±—É—é –ø–æ–∑–∏—Ü–∏—é
                if not position_match:
                    # print(f"üîß [PARAGRAPH] ‚ùå –ü–æ–∑–∏—Ü–∏—è –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    return False
                else:
                    # print(f"üîß [PARAGRAPH] ‚úÖ –ü–æ–∑–∏—Ü–∏—è –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∑–∞–º–µ–Ω—ã")
                    pass
            replacement_made = False
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ü—Ä—è–º–æ–π –ø–æ–∏—Å–∫ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π –≤ runs
            for i, run in enumerate(paragraph.runs):
                run_text = run.text or ''
                run_text_normalized = self._normalize_text(run_text)
                # print(f"üîß [PARAGRAPH] Run {i}: '{run_text}' (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω: '{run_text_normalized}')")
                # –ü—Ä–æ–±—É–µ–º –ø—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                if original_value in run_text or original_value_normalized in run_text_normalized:
                    # print(f"üîß [PARAGRAPH] ‚úÖ –ù–∞–π–¥–µ–Ω –≤ run {i}, –∑–∞–º–µ–Ω—è–µ–º")
                    # –ó–∞–º–µ–Ω—è–µ–º –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ç–µ–∫—Å—Ç–µ run'–∞
                    old_run_text = run.text
                    if original_value in run_text:
                        run.text = run_text.replace(original_value, replacement_value, 1)  # –ó–∞–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ
                    else:
                        # –ï—Å–ª–∏ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –µ—Å—Ç—å
                        run.text = self._replace_with_normalization(run_text, original_value, replacement_value)
                    replacement_made = True
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤—ã–¥–µ–ª–µ–Ω–∏–µ –∫ UUID
                    if self.highlight_replacements:
                        try:
                            run.font.highlight_color = self.replacement_color
                            # print(f"üîß [PARAGRAPH] ‚úÖ –ñ—ë–ª—Ç–æ–µ –≤—ã–¥–µ–ª–µ–Ω–∏–µ UUID –ø—Ä–∏–º–µ–Ω–µ–Ω–æ –∫ run {i}")
                        except Exception as e:
                            # print(f"üîß [PARAGRAPH] ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å –≤—ã–¥–µ–ª–µ–Ω–∏–µ: {e}")
                            pass
                    # print(f"üîß [PARAGRAPH] ‚úÖ –ó–∞–º–µ–Ω–∞ –≤ run {i} –∑–∞–≤–µ—Ä—à–µ–Ω–∞: '{old_run_text}' ‚Üí '{run.text}'")
                    # print(f"üîß [PARAGRAPH] üéØ –ó–∞–º–µ–Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞, –≤—ã—Ö–æ–¥–∏–º –∏–∑ –ø–æ–∏—Å–∫–∞")
                    break  # –í—ã—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–π —É—Å–ø–µ—à–Ω–æ–π –∑–∞–º–µ–Ω—ã
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö runs, –∏—â–µ–º –≤ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–∏ runs —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π
            if not replacement_made and len(paragraph.runs) > 1:
                # print(f"üîß [PARAGRAPH] –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ø–æ–∏—Å–∫ –≤ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–∏ runs —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π")
                # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –≤—Å–µ—Ö runs –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
                full_text = ''.join(run.text for run in paragraph.runs)
                full_text_normalized = self._normalize_text(full_text)
                # print(f"üîß [PARAGRAPH] –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ runs: '{full_text}'")
                # print(f"üîß [PARAGRAPH] –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç: '{full_text_normalized}'")
                if original_value in full_text or original_value_normalized in full_text_normalized:
                    # print(f"üîß [PARAGRAPH] ‚úÖ –ù–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–∏ runs")
                    # –ù–∞–π–¥–µ–º –ø–æ–∑–∏—Ü–∏—é –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º —Ç–µ–∫—Å—Ç–µ
                    search_text = original_value if original_value in full_text else original_value_normalized
                    search_target = full_text if original_value in full_text else full_text_normalized
                    start_pos = search_target.find(search_text)
                    end_pos = start_pos + len(search_text)
                    # print(f"üîß [PARAGRAPH] –ü–æ–∑–∏—Ü–∏—è –≤ –ø–æ–ª–Ω–æ–º —Ç–µ–∫—Å—Ç–µ: {start_pos}-{end_pos}")
                    # print(f"üîß [PARAGRAPH] Search text: '{search_text}'")
                    # print(f"üîß [PARAGRAPH] Search target: '{search_target}'")
                    # print(f"üîß [PARAGRAPH] Using normalized? {search_target == full_text_normalized}")
                    # –ï—Å–ª–∏ –º—ã —Ä–∞–±–æ—Ç–∞–µ–º —Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º, –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º
                    if search_target == full_text_normalized:
                        # print(f"üîß [PARAGRAPH] –í—ã–∑—ã–≤–∞–µ–º _replace_in_normalized_runs")
                        replacement_made = self._replace_in_normalized_runs(paragraph, original_value, replacement_value)
                    else:
                        # print(f"üîß [PARAGRAPH] –í—ã–∑—ã–≤–∞–µ–º _replace_across_runs")
                        replacement_made = self._replace_across_runs(paragraph, original_value, replacement_value, start_pos, end_pos)
                else:
                    # print(f"üîß [PARAGRAPH] ‚ùå –¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–∞–∂–µ –≤ –ø–æ–ª–Ω–æ–º —Ç–µ–∫—Å—Ç–µ runs")
                    pass
            if replacement_made:
                # print(f"üîß [PARAGRAPH] ‚úÖ –ó–∞–º–µ–Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                pass
            else:
                # print(f"üîß [PARAGRAPH] ‚ùå –ó–∞–º–µ–Ω–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
                pass
            return replacement_made
        except Exception as e:
            # print(f"üîß [PARAGRAPH] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–º–µ–Ω–µ –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ: {str(e)}")
            return False
    
    def _replace_with_normalization(self, run_text: str, original_value: str, replacement_value: str) -> str:
        """
        –ó–∞–º–µ–Ω–∞ —Ç–µ–∫—Å—Ç–∞ —Å —É—á–µ—Ç–æ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–±–µ–ª–æ–≤ (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ)
        """
        # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É –ø–æ–∑–∏—Ü–∏–π —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É
        normalized = self._normalize_text(run_text)
        original_normalized = self._normalize_text(original_value)
        
        if original_normalized in normalized:
            # –ü—Ä–æ—Å—Ç–∞—è –∑–∞–º–µ–Ω–∞, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç —Ç–æ—á–Ω–æ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
            # –ó–∞–º–µ–Ω—è–µ–º –≤—Å–µ –≤–∏–¥—ã –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ç–µ–∫—Å—Ç–µ –Ω–∞ –æ–±—ã—á–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
            result = run_text
            result = result.replace('\u00A0', ' ')  # –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–π –ø—Ä–æ–±–µ–ª
            result = result.replace('\u2009', ' ')  # —Ç–æ–Ω–∫–∏–π –ø—Ä–æ–±–µ–ª
            result = result.replace('\u2007', ' ')  # —Ü–∏—Ñ—Ä–æ–≤–æ–π –ø—Ä–æ–±–µ–ª
            result = result.replace('\u2008', ' ')  # –ø—É–Ω–∫—Ç—É–∞—Ü–∏–æ–Ω–Ω—ã–π –ø—Ä–æ–±–µ–ª
            result = result.replace('\u202F', ' ')  # —É–∑–∫–∏–π –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–π –ø—Ä–æ–±–µ–ª
            result = result.replace('\u3000', ' ')  # –∏–¥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–±–µ–ª
            
            # –¢–µ–ø–µ—Ä—å –∑–∞–º–µ–Ω—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ)
            if original_normalized in self._normalize_text(result):
                return result.replace(original_value, replacement_value, 1)
        
        return run_text
    
    def _replace_in_normalized_runs(self, paragraph, original_value: str, replacement_value: str) -> bool:
        """
        –ó–∞–º–µ–Ω–∞ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞–π–¥–µ–Ω —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–±–µ–ª–æ–≤
        """
        print(f"üîß [NORMALIZED_RUNS] –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–º–µ–Ω—É –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º —Ç–µ–∫—Å—Ç–µ")
        print(f"üîß [NORMALIZED_RUNS] –ò—Å–∫–æ–º—ã–π —Ç–µ–∫—Å—Ç: '{original_value}'")
        
        # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ –∑–∞–º–µ–Ω—è–µ–º –≤ –Ω–µ–º
        full_text = ''.join(run.text for run in paragraph.runs)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç 
        full_text_normalized = self._normalize_text(full_text)
        original_normalized = self._normalize_text(original_value)
        
        print(f"üîß [NORMALIZED_RUNS] –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç: '{full_text}'")
        print(f"üîß [NORMALIZED_RUNS] –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –ø–æ–ª–Ω—ã–π: '{full_text_normalized}'")
        print(f"üîß [NORMALIZED_RUNS] –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∏—Å–∫–æ–º—ã–π: '{original_normalized}'")
        
        if original_normalized not in full_text_normalized:
            print(f"üîß [NORMALIZED_RUNS] ‚ùå –¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–∞–∂–µ –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏")
            return False
        
        # –ù–∞–π–¥–µ–º –ø–æ–∑–∏—Ü–∏—é –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º —Ç–µ–∫—Å—Ç–µ
        normalized_start = full_text_normalized.find(original_normalized)
        normalized_end = normalized_start + len(original_normalized)
        
        print(f"üîß [NORMALIZED_RUNS] –ü–æ–∑–∏—Ü–∏—è –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º —Ç–µ–∫—Å—Ç–µ: {normalized_start}-{normalized_end}")
        
        # –¢–µ–ø–µ—Ä—å –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –ø–æ–∑–∏—Ü–∏—é –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ç–µ–∫—Å—Ç–µ
        # –°–æ–∑–¥–∞–¥–∏–º –∫–∞—Ä—Ç—É —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –º–µ–∂–¥—É –∏—Å—Ö–æ–¥–Ω—ã–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
        original_to_normalized = []
        normalized_pos = 0
        
        for original_pos, char in enumerate(full_text):
            if char in ['\u00A0', '\u2009', '\u2007', '\u2008', '\u202F', '\u3000']:
                # –ù–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã - –∑–∞–º–µ–Ω—è—é—Ç—Å—è –Ω–∞ –æ–±—ã—á–Ω—ã–π –ø—Ä–æ–±–µ–ª
                original_to_normalized.append(normalized_pos)
                normalized_pos += 1
            elif char.isspace():
                # –û–±—ã—á–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –æ—Å—Ç–∞—é—Ç—Å—è
                original_to_normalized.append(normalized_pos)
                normalized_pos += 1
            else:
                # –û–±—ã—á–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –æ—Å—Ç–∞—é—Ç—Å—è
                original_to_normalized.append(normalized_pos)
                normalized_pos += 1
        
        # –ù–∞–π–¥–µ–º –≥—Ä–∞–Ω–∏—Ü—ã –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ç–µ–∫—Å—Ç–µ
        original_start = None
        original_end = None
        
        for i, norm_pos in enumerate(original_to_normalized):
            if norm_pos == normalized_start and original_start is None:
                original_start = i
            if norm_pos == normalized_end - 1:
                original_end = i + 1
                break
        
        if original_start is None or original_end is None:
            print(f"üîß [NORMALIZED_RUNS] ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≥—Ä–∞–Ω–∏—Ü—ã –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ç–µ–∫—Å—Ç–µ")
            return False
        
        print(f"üîß [NORMALIZED_RUNS] –ü–æ–∑–∏—Ü–∏—è –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ç–µ–∫—Å—Ç–µ: {original_start}-{original_end}")
        
        # –¢–µ–ø–µ—Ä—å –∑–∞–º–µ–Ω—è–µ–º –ø–æ runs –∏—Å–ø–æ–ª—å–∑—É—è –ø–æ–∑–∏—Ü–∏—é –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ç–µ–∫—Å—Ç–µ
        return self._replace_across_runs(paragraph, original_value, replacement_value, original_start, original_end)
    
    def _replace_across_runs(self, paragraph, original_value: str, replacement_value: str, start_pos: int, end_pos: int) -> bool:
        """
        –ó–∞–º–µ–Ω–∞ —Ç–µ–∫—Å—Ç–∞, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º runs
        """
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ runs –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã
            current_pos = 0
            affected_runs = []
            for i, run in enumerate(paragraph.runs):
                run_start = current_pos
                run_end = current_pos + len(run.text)
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å –∏—Å–∫–æ–º—ã–º —Ç–µ–∫—Å—Ç–æ–º
                if not (run_end <= start_pos or run_start >= end_pos):
                    affected_runs.append({
                        'index': i,
                        'run': run,
                        'run_start': run_start,
                        'run_end': run_end,
                        'text_start': max(0, start_pos - run_start),
                        'text_end': min(len(run.text), end_pos - run_start)
                    })
                current_pos = run_end
            # print(f"üîß [PARAGRAPH] –ó–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ runs: {[r['index'] for r in affected_runs]}")
            if affected_runs:
                replacement_made = False
                # –ó–∞–º–µ–Ω—è–µ–º —Ç–µ–∫—Å—Ç –≤ –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã—Ö runs
                for i, run_info in enumerate(affected_runs):
                    run = run_info['run']
                    text_start = run_info['text_start']
                    text_end = run_info['text_end']
                    if i == 0:
                        # –ü–µ—Ä–≤—ã–π run - –¥–æ–±–∞–≤–ª—è–µ–º replacement_value
                        if text_start == 0 and text_end == len(run.text):
                            # –í–µ—Å—å run –∑–∞–º–µ–Ω—è–µ—Ç—Å—è
                            run.text = replacement_value
                        elif text_start == 0:
                            # –ó–∞–º–µ–Ω—è–µ–º –Ω–∞—á–∞–ª–æ
                            run.text = replacement_value + run.text[text_end:]
                        elif text_end == len(run.text):
                            # –ó–∞–º–µ–Ω—è–µ–º –∫–æ–Ω–µ—Ü
                            run.text = run.text[:text_start] + replacement_value
                        else:
                            # –ó–∞–º–µ–Ω—è–µ–º —Å–µ—Ä–µ–¥–∏–Ω—É
                            run.text = run.text[:text_start] + replacement_value + run.text[text_end:]
                        replacement_made = True
                        # print(f"üîß [PARAGRAPH] ‚úÖ Run {run_info['index']} –∑–∞–º–µ–Ω–µ–Ω")
                        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤—ã–¥–µ–ª–µ–Ω–∏–µ –∫ UUID
                        if self.highlight_replacements:
                            try:
                                run.font.highlight_color = self.replacement_color
                                # print(f"üîß [PARAGRAPH] ‚úÖ –ñ—ë–ª—Ç–æ–µ –≤—ã–¥–µ–ª–µ–Ω–∏–µ UUID –ø—Ä–∏–º–µ–Ω–µ–Ω–æ –∫ run {run_info['index']}")
                            except Exception as e:
                                # print(f"üîß [PARAGRAPH] ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å –≤—ã–¥–µ–ª–µ–Ω–∏–µ: {e}")
                                pass
                    else:
                        # –û—Å—Ç–∞–ª—å–Ω—ã–µ runs - —É–±–∏—Ä–∞–µ–º –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã–π —Ç–µ–∫—Å—Ç
                        if text_start == 0 and text_end == len(run.text):
                            # –í–µ—Å—å run —É–¥–∞–ª—è–µ—Ç—Å—è
                            run.text = ""
                        elif text_start == 0:
                            # –£–¥–∞–ª—è–µ–º –Ω–∞—á–∞–ª–æ
                            run.text = run.text[text_end:]
                        elif text_end == len(run.text):
                            # –£–¥–∞–ª—è–µ–º –∫–æ–Ω–µ—Ü
                            run.text = run.text[:text_start]
                        else:
                            # –£–¥–∞–ª—è–µ–º —Å–µ—Ä–µ–¥–∏–Ω—É (—Ä–µ–¥–∫–∏–π —Å–ª—É—á–∞–π)
                            run.text = run.text[:text_start] + run.text[text_end:]
                        # print(f"üîß [PARAGRAPH] ‚úÖ Run {run_info['index']} –æ–±—Ä–µ–∑–∞–Ω")
                        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤—ã–¥–µ–ª–µ–Ω–∏–µ, –µ—Å–ª–∏ –≤ run –µ—Å—Ç—å —Ç–µ–∫—Å—Ç
                        if self.highlight_replacements and run.text.strip():
                            try:
                                run.font.highlight_color = self.replacement_color
                                # print(f"üîß [PARAGRAPH] ‚úÖ –í—ã–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ –∫ –æ–±—Ä–µ–∑–∞–Ω–Ω–æ–º—É run {run_info['index']}")
                            except Exception as e:
                                # print(f"üîß [PARAGRAPH] ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å –≤—ã–¥–µ–ª–µ–Ω–∏–µ: {e}")
                                pass
                return replacement_made
            return False
        except Exception as e:
            # print(f"üîß [PARAGRAPH] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–º–µ–Ω–µ —á–µ—Ä–µ–∑ runs: {str(e)}")
            return False

    def _replace_in_table(self, table, original_value: str, replacement_value: str, position_info: dict = None) -> bool:
        """
        –ó–∞–º–µ–Ω–∞ —Ç–µ–∫—Å—Ç–∞ –≤ —Ç–∞–±–ª–∏—Ü–µ
        
        Args:
            table: –¢–∞–±–ª–∏—Ü–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            original_value: –ò—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            replacement_value: –ó–∞–º–µ—â–∞—é—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            position_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–∑–∏—Ü–∏–∏ –¥–ª—è —Ç–æ—á–Ω–æ–π –∑–∞–º–µ–Ω—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            True –µ—Å–ª–∏ –∑–∞–º–µ–Ω–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∞
        """
        try:
            print(f"üîß [TABLE] –ù–∞—á–∞–ª–æ –∑–∞–º–µ–Ω—ã –≤ —Ç–∞–±–ª–∏—Ü–µ: '{original_value}' ‚Üí '{replacement_value}'")
            print(f"üîß [TABLE] –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–∑–∏—Ü–∏–∏: {position_info}")
            replacement_made = False
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ü–æ–∑–∏—Ü–∏—è —É–∂–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –∫ –±–ª–æ–∫—É (—Ç–∞–±–ª–∏—Ü–µ), –Ω–µ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞—Ç—å!
            target_position = position_info.get('start') if position_info else None
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ–∑–∏—Ü–∏–∏
            table_text = ""
            cell_positions = []  # –ú–∞–ø–∏–º –ø–æ–∑–∏—Ü–∏–∏ –Ω–∞ —è—á–µ–π–∫–∏
            
            for row_idx, row in enumerate(table.rows):
                for cell_idx, cell in enumerate(row.cells):
                    cell_text = getattr(cell, 'text', '') or ''
                    cell_start = len(table_text)
                    table_text += cell_text
                    cell_end = len(table_text)
                    
                    cell_positions.append({
                        'row': row_idx,
                        'col': cell_idx,
                        'start': cell_start,
                        'end': cell_end,
                        'cell': cell,
                        'text': cell_text
                    })
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –∫–∞–∫ –≤ BlockBuilder
                    if cell_idx < len(row.cells) - 1:
                        table_text += " | "
                    
                # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
                table_text += "\n"
            
            print(f"üîß [TABLE] –¢–µ–∫—Å—Ç —Ç–∞–±–ª–∏—Ü—ã ({len(table_text)} —Å–∏–º–≤–æ–ª–æ–≤): '{table_text[:100]}...'")
            print(f"üîß [TABLE] –ò—â–µ–º '{original_value}' –Ω–∞ –ø–æ–∑–∏—Ü–∏–∏ {target_position}")
            
            # –ù–∞—Ö–æ–¥–∏–º —è—á–µ–π–∫—É –ø–æ –ø–æ–∑–∏—Ü–∏–∏
            # –ö–†–ò–¢–ò–ß–ù–û: –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ (–∑–∞–º–µ–Ω—è–µ–º \xa0 –Ω–∞ –æ–±—ã—á–Ω—ã–π –ø—Ä–æ–±–µ–ª)
            normalized_original = self._normalize_text(original_value)
            
            target_cell = None
            for cell_info in cell_positions:
                normalized_cell_text = self._normalize_text(cell_info['text'])
                if normalized_original in normalized_cell_text:
                    # –ï—Å–ª–∏ –ø–æ–∑–∏—Ü–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω–∞, –±–µ—Ä—ë–º –ø–µ—Ä–≤—É—é –Ω–∞–π–¥–µ–Ω–Ω—É—é
                    if target_position is None:
                        target_cell = cell_info
                        print(f"üîß [TABLE] ‚úÖ –ù–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç –≤ —è—á–µ–π–∫–µ [{cell_info['row']}][{cell_info['col']}] (–±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–∑–∏—Ü–∏–∏)")
                        break
                    else:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ–∑–∏—Ü–∏—è –ø–æ–ø–∞–¥–∞–µ—Ç –≤ –¥–∏–∞–ø–∞–∑–æ–Ω —è—á–µ–π–∫–∏
                        if cell_info['start'] <= target_position < cell_info['end']:
                            target_cell = cell_info
                            print(f"üîß [TABLE] ‚úÖ –ù–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç –≤ —è—á–µ–π–∫–µ [{cell_info['row']}][{cell_info['col']}] –Ω–∞ –ø–æ–∑–∏—Ü–∏–∏ {target_position}")
                            break
            
            if not target_cell:
                print(f"üîß [TABLE] ‚ùå –¢–µ–∫—Å—Ç '{original_value}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–∞–±–ª–∏—Ü–µ")
                return False
            
            # –ó–∞–º–µ–Ω—è–µ–º –≤ –Ω–∞–π–¥–µ–Ω–Ω–æ–π —è—á–µ–π–∫–µ
            cell = target_cell['cell']
            for para_idx, paragraph in enumerate(cell.paragraphs):
                paragraph_text = getattr(paragraph, 'text', '') or ''
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π —Ç–µ–∫—Å—Ç–∞
                if original_value and (original_value in paragraph_text or 
                                      normalized_original in self._normalize_text(paragraph_text)):
                    print(f"üîß [TABLE] –ó–∞–º–µ–Ω–∞ –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ {para_idx} —è—á–µ–π–∫–∏ [{target_cell['row']}][{target_cell['col']}]")
                    cell_replacement_made = self._replace_in_paragraph(
                        paragraph, original_value, replacement_value, {}
                    )
                    if cell_replacement_made:
                        replacement_made = True
                        print(f"üîß [TABLE] ‚úÖ –ó–∞–º–µ–Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                        return True
                    else:
                        print(f"üîß [TABLE] ‚ùå –ó–∞–º–µ–Ω–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å")
            
            return replacement_made
            
        except Exception as e:
            print(f"üîß [TABLE] ‚ùå –û—à–∏–±–∫–∞ –∑–∞–º–µ–Ω—ã –≤ —Ç–∞–±–ª–∏—Ü–µ: {str(e)}")
            import traceback
            print(f"üîß [TABLE] Traceback: {traceback.format_exc()}")
            return False
    
    def _generate_replacement_value(self, original_value: str, category: str, existing_uuid: str = None) -> str:
        """
        üéØ –¶–ï–ù–¢–†–ê–õ–ò–ó–û–í–ê–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–º–µ—â–∞—é—â–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
        
        Args:
            original_value: –ò—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            existing_uuid: –°—É—â–µ—Å—Ç–≤—É—é—â–∏–π UUID –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            
        Returns:
            UUID –¥–ª—è –∑–∞–º–µ—â–µ–Ω–∏—è
        """
        
        # –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Å—Ç–∏—á–µ—Å–∫–∏–π UUID
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è contract_number –∏ information_system –û–¢–ö–õ–Æ–ß–ï–ù–ê
        return self.uuid_mapper.get_uuid_for_text(original_value, category)
    
    def _generate_contract_number_replacement(self, original_number: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–º–µ—â–∞—é—â–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –Ω–æ–º–µ—Ä–æ–≤ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        
        # –ü–æ–ª—É—á–∞–µ–º –±–∞–∑–æ–≤—ã–π UUID –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        base_uuid = self.uuid_mapper.get_uuid_for_text(original_number, 'contract_number')
        short_id = base_uuid.replace('-', '')[:8].upper()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –Ω–æ–º–µ—Ä–∞
        if '/' in original_number:
            parts = original_number.split('/')
            if len(parts) == 2:
                return f"{short_id[:2]}/{parts[1]}"
        elif '-' in original_number:
            parts = original_number.split('-')
            if len(parts) >= 2:
                return f"{short_id[:2]}-{'-'.join(parts[1:])}"
        
        # –î–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –Ω–æ–º–µ—Ä–æ–≤ - –ø–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞
        return short_id
    
    def _generate_information_system_replacement(self, original_value: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–º–µ—â–∞—é—â–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º"""
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–º
        if '[SYSTEM_ID]' in original_value:
            # –ó–∞–º–µ–Ω—è–µ–º –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–π UUID
            base_uuid = self.uuid_mapper.get_uuid_for_text(original_value, 'information_system')
            short_id = base_uuid.replace('-', '')[:8].upper()
            return original_value.replace('[SYSTEM_ID]', short_id)
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∑–∞–º–µ–Ω–∞
        return self.uuid_mapper.get_uuid_for_text(original_value, 'information_system')
    
    def generate_replacement_report(self, replacements: List[Dict]) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–Ω—ã—Ö –∑–∞–º–µ–Ω–∞—Ö
        
        Args:
            replacements: –°–ø–∏—Å–æ–∫ –∑–∞–º–µ–Ω
            
        Returns:
            –û—Ç—á–µ—Ç –æ –∑–∞–º–µ–Ω–∞—Ö
        """
        report = {
            'total_replacements': len(replacements),
            'categories': {},
            'confidence_stats': {
                'high': 0,  # > 0.8
                'medium': 0,  # 0.5 - 0.8  
                'low': 0    # < 0.5
            }
        }
        
        for replacement in replacements:
            # –ü–æ–¥—Å—á–µ—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            category = replacement.get('category', 'unknown')
            if category not in report['categories']:
                report['categories'][category] = 0
            report['categories'][category] += 1
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            confidence = replacement.get('confidence', 1.0)
            if confidence > 0.8:
                report['confidence_stats']['high'] += 1
            elif confidence > 0.5:
                report['confidence_stats']['medium'] += 1
            else:
                report['confidence_stats']['low'] += 1
        
        return report
    
    def _normalize_replacements_with_centralized_uuids(self, replacements: List[Dict]) -> List[Dict]:
        """
        üéØ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–º–µ–Ω —Å —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π UUID
        
        Args:
            replacements: –ò—Å—Ö–æ–¥–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∑–∞–º–µ–Ω
            
        Returns:
            –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–º–∏ UUID
        """
        normalized = []
        
        for replacement in replacements:
            original_value = replacement.get('original_value', '')
            category = replacement.get('category', 'data')
            
            if not original_value:
                normalized.append(replacement)
                continue
                
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –∑–∞–º–µ–Ω—ã
            normalized_replacement = replacement.copy()
            
            # üéØ –û–ë–†–ê–ë–ê–¢–´–í–ê–ï–ú –ê–ù–û–ù–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –¢–ï–ö–°–¢ (–µ—Å–ª–∏ –µ—Å—Ç—å)
            anonymized_text = replacement.get('anonymized_text')
            if anonymized_text:
                # –ï—Å–ª–∏ –µ—Å—Ç—å –≥–æ—Ç–æ–≤—ã–π –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ –æ—Å–Ω–æ–≤—É
                centralized_uuid = self._generate_replacement_value(anonymized_text, category, None)
                normalized_replacement['uuid'] = centralized_uuid
            else:
                # üéØ –ì–ï–ù–ï–†–ò–†–£–ï–ú –¶–ï–ù–¢–†–ê–õ–ò–ó–û–í–ê–ù–ù–´–ô UUID
                centralized_uuid = self.uuid_mapper.get_uuid_for_text(original_value, category)
                normalized_replacement['uuid'] = centralized_uuid
            
            normalized.append(normalized_replacement)
        
        return normalized
    
    def apply_complete_anonymization(self, docx_path: str, output_path: str, replacements: List[Dict]) -> Dict[str, Any]:
        """
        üéØ –ü–û–õ–ù–ê–Ø –ê–ù–û–ù–ò–ú–ò–ó–ê–¶–ò–Ø: –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—è —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç:
        1. –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã, —Ç–∞–±–ª–∏—Ü—ã)
        2. –ó–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª—ã (—Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç + SDT)
        3. –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (docProps/core.xml, app.xml, custom.xml)
        
        Args:
            docx_path: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É DOCX —Ñ–∞–π–ª—É
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            replacements: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∑–∞–º–µ–Ω
            
        Returns:
            –ü–æ–ª–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏–∏
        """
        print(f"üéÜ [COMPLETE_ANONYMIZATION] –ù–∞—á–∞–ª–æ –ø–æ–ª–Ω–æ–π –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏–∏")
        print(f"üìÑ Input: {docx_path}")
        print(f"üìÑ Output: {output_path}")
        print(f"üéØ –ó–∞–º–µ–Ω –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(replacements)}")
        
        total_stats = {
            'total_replacements': 0,
            'categories': {},
            'blocks_processed': 0,
            'headers_footers_processed': 0,
            'metadata_replacements': 0,
            'replacement_details': [],
            'phases': {
                'document_content': {},
                'headers_footers': {},
                'metadata': {}
            }
        }
        
        try:
            from docx import Document
            import tempfile
            import os
            
            # –≠—Ç–∞–ø 1: –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            print(f"üéÜ [PHASE 1] –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
            doc = Document(docx_path)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–º–µ–Ω—ã
            normalized_replacements = self._normalize_replacements_with_centralized_uuids(replacements)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—é –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É
            content_stats = self.apply_replacements_to_document(doc, normalized_replacements)
            total_stats['phases']['document_content'] = content_stats
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            with tempfile.NamedTemporaryFile(suffix='.docx', delete=False) as temp_file:
                doc.save(temp_file.name)
                intermediate_docx = temp_file.name
            
            print(f"üéÜ [PHASE 1] ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ. –ó–∞–º–µ–Ω: {content_stats['total_replacements']}")
            
            # –≠—Ç–∞–ø 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            print(f"üéÜ [PHASE 2] –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞")
            
            metadata_handler = DocxMetadataHandler(intermediate_docx)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata = metadata_handler.extract_metadata()
            
            # –ò—â–µ–º —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            sensitive_metadata = metadata_handler.find_sensitive_metadata(normalized_replacements)
            
            # –ê–Ω–æ–Ω–∏–º–∏–∑–∏—Ä—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            metadata_success = metadata_handler.anonymize_metadata_in_docx(
                intermediate_docx, output_path, sensitive_metadata
            )
            
            if metadata_success:
                total_stats['metadata_replacements'] = len(sensitive_metadata)
                total_stats['phases']['metadata'] = {
                    'sensitive_found': len(sensitive_metadata),
                    'success': True
                }
                print(f"üéÜ [PHASE 2] ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ. –ó–∞–º–µ–Ω –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {len(sensitive_metadata)}")
            else:
                print(f"üéÜ [PHASE 2] ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö")
                # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –∫–æ–ø–∏—Ä—É–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                import shutil
                shutil.copy2(intermediate_docx, output_path)
                total_stats['phases']['metadata'] = {
                    'sensitive_found': len(sensitive_metadata),
                    'success': False,
                    'error': '–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö'
                }
            
            # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if os.path.exists(intermediate_docx):
                os.remove(intermediate_docx)
            
            # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            total_stats['total_replacements'] = (
                content_stats['total_replacements'] + 
                total_stats['metadata_replacements']
            )
            total_stats['categories'] = content_stats['categories']
            total_stats['blocks_processed'] = content_stats['blocks_processed']
            total_stats['headers_footers_processed'] = content_stats.get('headers_footers_processed', 0)
            total_stats['replacement_details'] = content_stats['replacement_details']
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ –¥–µ—Ç–∞–ª–∏
            for metadata_item in sensitive_metadata:
                total_stats['replacement_details'].append({
                    'uuid': metadata_item.get('uuid'),
                    'category': metadata_item.get('category'),
                    'original_value': metadata_item.get('original_value'),
                    'source': 'metadata',
                    'metadata_section': metadata_item.get('metadata_section'),
                    'metadata_property': metadata_item.get('metadata_property'),
                    'success': True
                })
            
            print(f"üéÜ [COMPLETE_ANONYMIZATION] ‚úÖ –ü–û–õ–ù–ê–Ø –ê–ù–û–ù–ò–ú–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê")
            print(f"üìà –û–±—â–∏–π –∏—Ç–æ–≥:")
            print(f"  üî¢ –í—Å–µ–≥–æ –∑–∞–º–µ–Ω: {total_stats['total_replacements']}")
            print(f"  üìÑ –ó–∞–º–µ–Ω –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ: {content_stats['total_replacements']}")
            print(f"  üìÑ –ó–∞–º–µ–Ω –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {total_stats['metadata_replacements']}")
            print(f"  üìù –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –±–ª–æ–∫–æ–≤: {total_stats['blocks_processed']}")
            print(f"  üìù Headers/Footers: {total_stats['headers_footers_processed']}")
            
            return total_stats
            
        except Exception as e:
            print(f"üéÜ [COMPLETE_ANONYMIZATION] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª–Ω–æ–π –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏–∏: {str(e)}")
            import traceback
            print(f"üéÜ [COMPLETE_ANONYMIZATION] Traceback: {traceback.format_exc()}")
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            return {
                'total_replacements': 0,
                'categories': {},
                'blocks_processed': 0,
                'headers_footers_processed': 0,
                'metadata_replacements': 0,
                'replacement_details': [],
                'error': str(e)
            }
    
    def _apply_replacements_to_headers_footers(self, doc, replacements: List[Dict]) -> Dict[str, Any]:
        """
        üéØ –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∑–∞–º–µ–Ω –∫ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º –∏ –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–∞–º –¥–æ–∫—É–º–µ–Ω—Ç–∞
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ü–û–°–õ–ï –æ—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è
        
        Args:
            doc: –î–æ–∫—É–º–µ–Ω—Ç DOCX
            replacements: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∑–∞–º–µ–Ω —Å –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–º–∏ UUID
            
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–º–µ–Ω –≤ headers/footers
        """
        stats = {
            'total_replacements': 0,
            'categories': {},
            'headers_footers_processed': 0,
            'replacement_details': []
        }
        
        try:
            # –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–º–µ–Ω—ã –¥–ª—è headers/footers (–ø–æ —Ç–∏–ø—É –±–ª–æ–∫–∞)
            header_footer_replacements = []
            for replacement in replacements:
                block_id = replacement.get('block_id', '')
                if any(block_type in block_id for block_type in ['header_', 'footer_']):
                    header_footer_replacements.append(replacement)
            
            print(f"üîß [HEADERS_FOOTERS] –ù–∞–π–¥–µ–Ω–æ –∑–∞–º–µ–Ω –¥–ª—è headers/footers: {len(header_footer_replacements)}")
            
            if not header_footer_replacements:
                print(f"üîß [HEADERS_FOOTERS] ‚ö†Ô∏è –ù–µ—Ç –∑–∞–º–µ–Ω –¥–ª—è headers/footers")
                return stats
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å–µ–∫—Ü–∏—é –¥–æ–∫—É–º–µ–Ω—Ç–∞
            for section_idx, section in enumerate(doc.sections):
                print(f"üîß [HEADERS_FOOTERS] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ–∫—Ü–∏—é {section_idx}")
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º header —Å–µ–∫—Ü–∏–∏
                if section.header:
                    header_stats = self._apply_replacements_to_header_footer(
                        section.header, header_footer_replacements, section_idx, 'header'
                    )
                    stats['total_replacements'] += header_stats['replacements_made']
                    stats['replacement_details'].extend(header_stats['details'])
                    
                    # –ü–æ–¥—Å—á–µ—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                    for replacement in header_footer_replacements:
                        if replacement.get('block_id', '').startswith(f'header_{section_idx}'):
                            category = replacement.get('category', 'unknown')
                            if category not in stats['categories']:
                                stats['categories'][category] = 0
                            stats['categories'][category] += 1
                    
                    if header_stats['replacements_made'] > 0:
                        stats['headers_footers_processed'] += 1
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º footer —Å–µ–∫—Ü–∏–∏
                if section.footer:
                    footer_stats = self._apply_replacements_to_header_footer(
                        section.footer, header_footer_replacements, section_idx, 'footer'
                    )
                    stats['total_replacements'] += footer_stats['replacements_made']
                    stats['replacement_details'].extend(footer_stats['details'])
                    
                    # –ü–æ–¥—Å—á–µ—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                    for replacement in header_footer_replacements:
                        if replacement.get('block_id', '').startswith(f'footer_{section_idx}'):
                            category = replacement.get('category', 'unknown')
                            if category not in stats['categories']:
                                stats['categories'][category] = 0
                            stats['categories'][category] += 1
                    
                    if footer_stats['replacements_made'] > 0:
                        stats['headers_footers_processed'] += 1
            
            print(f"üîß [HEADERS_FOOTERS] ‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í—Å–µ–≥–æ –∑–∞–º–µ–Ω: {stats['total_replacements']}")
            return stats
            
        except Exception as e:
            print(f"üîß [HEADERS_FOOTERS] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ headers/footers: {str(e)}")
            import traceback
            print(f"üîß [HEADERS_FOOTERS] Traceback: {traceback.format_exc()}")
            return stats
    
    def _apply_replacements_to_header_footer(self, container, replacements: List[Dict], 
                                           section_idx: int, container_type: str) -> Dict[str, Any]:
        """
        –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∑–∞–º–µ–Ω –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É header –∏–ª–∏ footer
        
        Args:
            container: Header –∏–ª–∏ Footer –æ–±—ä–µ–∫—Ç
            replacements: –°–ø–∏—Å–æ–∫ –∑–∞–º–µ–Ω
            section_idx: –ò–Ω–¥–µ–∫—Å —Å–µ–∫—Ü–∏–∏
            container_type: 'header' –∏–ª–∏ 'footer'
            
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–º–µ–Ω –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
        """
        container_stats = {
            'replacements_made': 0,
            'details': []
        }
        
        try:
            print(f"üîß [{container_type.upper()}] –û–±—Ä–∞–±–æ—Ç–∫–∞ {container_type} —Å–µ–∫—Ü–∏–∏ {section_idx}")
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–º–µ–Ω—ã –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
            relevant_replacements = []
            for replacement in replacements:
                block_id = replacement.get('block_id', '')
                if block_id.startswith(f'{container_type}_{section_idx}'):
                    relevant_replacements.append(replacement)
            
            print(f"üîß [{container_type.upper()}] –ù–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–∞–º–µ–Ω: {len(relevant_replacements)}")
            
            if not relevant_replacements:
                return container_stats
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∑–∞–º–µ–Ω—ã –ø–æ –ø–æ–∑–∏—Ü–∏–∏ (–≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ)
            relevant_replacements.sort(key=lambda x: x.get('position', {}).get('start', 0), reverse=True)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –∑–∞–º–µ–Ω—ã –∫ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
            for paragraph in container.paragraphs:
                paragraph_text = getattr(paragraph, 'text', '') or ''
                print(f"üîß [{container_type.upper()}] –ü–∞—Ä–∞–≥—Ä–∞—Ñ: '{paragraph_text[:100]}{'...' if len(paragraph_text) > 100 else ''}'")
                
                for replacement in relevant_replacements:
                    original_value = replacement.get('original_value', '')
                    
                    if original_value and original_value in paragraph_text:
                        print(f"üîß [{container_type.upper()}] ‚úÖ –ù–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç –¥–ª—è –∑–∞–º–µ–Ω—ã: '{original_value}'")
                        
                        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∑–∞–º–µ–Ω—É –∏—Å–ø–æ–ª—å–∑—É—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥
                        success = self._replace_in_paragraph(
                            paragraph, 
                            original_value, 
                            replacement.get('uuid', ''),
                            replacement.get('position', {})
                        )
                        
                        if success:
                            container_stats['replacements_made'] += 1
                            container_stats['details'].append({
                                'uuid': replacement.get('uuid'),
                                'category': replacement.get('category'),
                                'original_value': original_value,
                                'container_type': container_type,
                                'section_idx': section_idx,
                                'success': True
                            })
                            print(f"üîß [{container_type.upper()}] ‚úÖ –ó–∞–º–µ–Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                        else:
                            container_stats['details'].append({
                                'uuid': replacement.get('uuid'),
                                'category': replacement.get('category'),
                                'original_value': original_value,
                                'container_type': container_type,
                                'section_idx': section_idx,
                                'success': False,
                                'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–º–µ–Ω—É –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ'
                            })
                            print(f"üîß [{container_type.upper()}] ‚ùå –ó–∞–º–µ–Ω–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
            
            # üéØ –ö–†–ò–¢–ò–ß–ù–û: –û–±—Ä–∞–±–æ—Ç–∫–∞ SDT —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (Structured Document Tags)
            # –≠—Ç–∏ —ç–ª–µ–º–µ–Ω—Ç—ã —á–∞—Å—Ç–æ —Å–æ–¥–µ—Ä–∂–∞—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö
            sdt_stats = self._apply_replacements_to_sdt_elements(container, relevant_replacements, container_type, section_idx)
            container_stats['replacements_made'] += sdt_stats['replacements_made']
            container_stats['details'].extend(sdt_stats['details'])
            
            print(f"üîß [{container_type.upper()}] –ò—Ç–æ–≥–æ –∑–∞–º–µ–Ω –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ: {container_stats['replacements_made']}")
            return container_stats
            
        except Exception as e:
            print(f"üîß [{container_type.upper()}] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞: {str(e)}")
            return container_stats
    
    def _apply_replacements_to_sdt_elements(self, container, replacements: List[Dict], 
                                          container_type: str, section_idx: int) -> Dict[str, Any]:
        """
        üéØ –ö–†–ò–¢–ò–ß–ù–û: –û–±—Ä–∞–±–æ—Ç–∫–∞ SDT (Structured Document Tags) —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö/–∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–∞—Ö
        SDT —ç–ª–µ–º–µ–Ω—Ç—ã —á–∞—Å—Ç–æ —Å–æ–¥–µ—Ä–∂–∞—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å
        
        Args:
            container: Header –∏–ª–∏ Footer –æ–±—ä–µ–∫—Ç
            replacements: –°–ø–∏—Å–æ–∫ –∑–∞–º–µ–Ω –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
            container_type: 'header' –∏–ª–∏ 'footer'
            section_idx: –ò–Ω–¥–µ–∫—Å —Å–µ–∫—Ü–∏–∏
            
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–º–µ–Ω –≤ SDT —ç–ª–µ–º–µ–Ω—Ç–∞—Ö
        """
        sdt_stats = {
            'replacements_made': 0,
            'details': []
        }
        
        try:
            print(f"üîß [SDT-{container_type.upper()}] –ü–æ–∏—Å–∫ SDT —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ {container_type} —Å–µ–∫—Ü–∏–∏ {section_idx}")
            
            # –ò—â–µ–º SDT —ç–ª–µ–º–µ–Ω—Ç—ã –≤ XML —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
            if hasattr(container, '_element'):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º try/except –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                try:
                    # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å xpath —Å namespaces (–¥–ª—è lxml.etree._Element)
                    sdt_elements = container._element.xpath('.//w:sdt', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'})
                except TypeError:
                    # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º xpath –±–µ–∑ namespaces (–¥–ª—è BaseOxmlElement)
                    sdt_elements = container._element.xpath('.//w:sdt')
                
                print(f"üîß [SDT-{container_type.upper()}] –ù–∞–π–¥–µ–Ω–æ SDT —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(sdt_elements)}")
                
                for sdt_idx, sdt_element in enumerate(sdt_elements):
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ SDT —ç–ª–µ–º–µ–Ω—Ç–∞
                    try:
                        # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å xpath —Å namespaces
                        text_elements = sdt_element.xpath('.//w:t', namespaces={'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'})
                    except TypeError:
                        # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º xpath –±–µ–∑ namespaces
                        text_elements = sdt_element.xpath('.//w:t')
                    
                    for text_element in text_elements:
                        current_text = text_element.text or ''
                        print(f"üîß [SDT-{container_type.upper()}] SDT —Ç–µ–∫—Å—Ç: '{current_text}'")
                        
                        # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∑–∞–º–µ–Ω—ã
                        for replacement in replacements:
                            original_value = replacement.get('original_value', '')
                            
                            if original_value and original_value in current_text:
                                print(f"üîß [SDT-{container_type.upper()}] ‚úÖ –ù–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç –¥–ª—è –∑–∞–º–µ–Ω—ã –≤ SDT: '{original_value}'")
                                
                                # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–º–µ–Ω—É –≤ SDT —ç–ª–µ–º–µ–Ω—Ç–µ
                                new_text = current_text.replace(original_value, replacement.get('uuid', ''), 1)
                                text_element.text = new_text
                                
                                sdt_stats['replacements_made'] += 1
                                sdt_stats['details'].append({
                                    'uuid': replacement.get('uuid'),
                                    'category': replacement.get('category'),
                                    'original_value': original_value,
                                    'container_type': f'{container_type}_sdt',
                                    'section_idx': section_idx,
                                    'sdt_idx': sdt_idx,
                                    'success': True
                                })
                                
                                print(f"üîß [SDT-{container_type.upper()}] ‚úÖ –ó–∞–º–µ–Ω–∞ –≤ SDT –≤—ã–ø–æ–ª–Ω–µ–Ω–∞: '{current_text}' ‚Üí '{new_text}'")
                                break  # –ó–∞–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ
            
            print(f"üîß [SDT-{container_type.upper()}] –ó–∞–º–µ–Ω –≤ SDT —ç–ª–µ–º–µ–Ω—Ç–∞—Ö: {sdt_stats['replacements_made']}")
            return sdt_stats
            
        except Exception as e:
            print(f"üîß [SDT-{container_type.upper()}] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ SDT —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {str(e)}")
            return sdt_stats