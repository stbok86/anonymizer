"""
–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è –ø–æ–∏—Å–∫–∞ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π NLP —Å–µ—Ä–≤–∏—Å–∞
"""

import re
import uuid
import requests
import pandas as pd
from typing import List, Dict, Any, Optional, Tuple


class RuleEngineAdapter:
    def __init__(self, patterns_file: str = None, nlp_service_url: str = "http://localhost:8003"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–¥–∞–ø—Ç–µ—Ä–∞ –ø—Ä–∞–≤–∏–ª –ø–æ–∏—Å–∫–∞
        
        Args:
            patterns_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏ (Excel/CSV)
            nlp_service_url: URL NLP —Å–µ—Ä–≤–∏—Å–∞ –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        """
        self.patterns_file = patterns_file or "patterns/sensitive_patterns.xlsx"
        self.nlp_service_url = nlp_service_url
        self.patterns = self._load_patterns()
        
    def _load_patterns(self) -> Dict[str, List[Dict]]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¢–û–õ–¨–ö–û –∏–∑ XLSX —Ñ–∞–π–ª–∞
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        """
        print(f"üîç [INFO] –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑: {self.patterns_file}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        patterns = {}
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¢–û–õ–¨–ö–û –∏–∑ —Ñ–∞–π–ª–∞
        try:
            if self.patterns_file and pd is not None:
                print(f"üîç [DEBUG] Pandas –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª: {self.patterns_file}")
                import os
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
                if not os.path.exists(self.patterns_file):
                    print(f"‚ùå [ERROR] –§–∞–π–ª –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.patterns_file}")
                    print(f"üîç [DEBUG] –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å...")
                    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–µ–∫—É—â–µ–≥–æ –º–æ–¥—É–ª—è
                    current_dir = os.path.dirname(os.path.abspath(__file__))
                    relative_path = os.path.join(current_dir, "..", self.patterns_file)
                    absolute_path = os.path.abspath(relative_path)
                    print(f"üîç [DEBUG] –ü—Ä–æ–±—É–µ–º –ø—É—Ç—å: {absolute_path}")
                    
                    if os.path.exists(absolute_path):
                        self.patterns_file = absolute_path
                        print(f"‚úÖ [SUCCESS] –§–∞–π–ª –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {self.patterns_file}")
                    else:
                        print(f"‚ùå [ERROR] –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –∏ –ø–æ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–º—É –ø—É—Ç–∏: {absolute_path}")
                        print("üîç [DEBUG] –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã")
                        return patterns
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
                file_ext = os.path.splitext(self.patterns_file.lower())[1]
                print(f"üîç [DEBUG] –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞: {file_ext}")
                
                # –û—Å–æ–±–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: –µ—Å–ª–∏ —Ñ–∞–π–ª .xlsx –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∫–∞–∫ Excel, –ø—Ä–æ–±—É–µ–º –∫–∞–∫ CSV
                if file_ext == '.xlsx' and not self._is_valid_excel(self.patterns_file):
                    print(f"üîç [DEBUG] –§–∞–π–ª {self.patterns_file} –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º Excel, –ø—Ä–æ–±—É–µ–º –∫–∞–∫ CSV...")
                    try:
                        df = pd.read_csv(self.patterns_file)
                        print(f"‚úÖ [SUCCESS] –ó–∞–≥—Ä—É–∂–µ–Ω—ã –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞ {self.patterns_file} –∫–∞–∫ CSV")
                    except Exception as csv_e:
                        print(f"‚ùå [ERROR] –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–∫ CSV: {csv_e}")
                        df = None
                elif file_ext == '.csv':
                    print(f"üîç [DEBUG] –ó–∞–≥—Ä—É–∂–∞–µ–º CSV —Ñ–∞–π–ª...")
                    df = pd.read_csv(self.patterns_file)
                    print(f"‚úÖ [SUCCESS] –ó–∞–≥—Ä—É–∂–µ–Ω—ã –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ CSV —Ñ–∞–π–ª–∞: {self.patterns_file}")
                elif file_ext in ['.xlsx', '.xls']:
                    print(f"üîç [DEBUG] –ó–∞–≥—Ä—É–∂–∞–µ–º Excel —Ñ–∞–π–ª...")
                    df = pd.read_excel(self.patterns_file)
                    print(f"‚úÖ [SUCCESS] –ó–∞–≥—Ä—É–∂–µ–Ω—ã –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ Excel —Ñ–∞–π–ª–∞: {self.patterns_file}")
                else:
                    print(f"‚ùå [ERROR] –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file_ext}")
                    df = None
                
                if df is not None:
                    print(f"üîç [DEBUG] DataFrame —Å–æ–∑–¥–∞–Ω, —Å—Ç—Ä–æ–∫: {len(df)}")
                    print(f"üîç [DEBUG] –°—Ç–æ–ª–±—Ü—ã DataFrame: {list(df.columns)}")
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞ –∫ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º
                    patterns_added = 0
                    for i, (_, row) in enumerate(df.iterrows()):
                        category = row.get('category', 'unknown').lower()
                        pattern = row.get('pattern', '')
                        description = row.get('description', '')
                        confidence = float(row.get('confidence', 0.5))
                        
                        print(f"üîç [DEBUG] –°—Ç—Ä–æ–∫–∞ {i+1}: category={category}, pattern='{pattern[:50]}...', confidence={confidence}")
                        
                        if pattern:  # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω –Ω–µ –ø—É—Å—Ç–æ–π
                            if category not in patterns:
                                patterns[category] = []
                                print(f"üîç [DEBUG] –°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {category}")
                            
                            patterns[category].append({
                                'pattern': pattern,
                                'description': description,
                                'confidence': confidence
                            })
                            patterns_added += 1
                    
                    print(f"‚úÖ [SUCCESS] –î–æ–±–∞–≤–ª–µ–Ω–æ {patterns_added} –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞")
                    print(f"üîç [DEBUG] –ò—Ç–æ–≥–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {len(patterns)}")
                    for category, patterns_list in patterns.items():
                        print(f"üîç [DEBUG]   {category}: {len(patterns_list)} –ø—Ä–∞–≤–∏–ª")
                        
            else:
                if not self.patterns_file:
                    print(f"‚ùå [ERROR] –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–µ —É–∫–∞–∑–∞–Ω")
                if pd is None:
                    print(f"‚ùå [ERROR] Pandas –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
                
                print("‚ùå [ERROR] –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —É–¥–∞–ª–µ–Ω—ã! –í—Å–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ XLSX —Ñ–∞–π–ª–µ!")
                print("üö® [ERROR] –°–∏—Å—Ç–µ–º–∞ –Ω–µ –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ —Ñ–∞–π–ª–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤!")
                return {}
                    
        except Exception as e:
            print(f"‚ùå [ERROR] –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞ {self.patterns_file}: {e}")
            import traceback
            traceback.print_exc()
            print("‚ùå [ERROR] –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —É–¥–∞–ª–µ–Ω—ã! –í—Å–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ XLSX —Ñ–∞–π–ª–µ!")
            print("üö® [ERROR] –°–∏—Å—Ç–µ–º–∞ –Ω–µ –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ —Ñ–∞–π–ª–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤!")
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å - —Å–∏—Å—Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ —Ç—Ä–µ–±–æ–≤–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–∞–π–ª
            return {}
        
        return patterns
    
    def _is_valid_excel(self, file_path: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –≤–∞–ª–∏–¥–Ω—ã–º Excel —Ñ–∞–π–ª–æ–º"""
        try:
            # –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–∫ Excel
            pd.read_excel(file_path, nrows=1)
            return True
        except Exception:
            return False
    
    def apply_rules_to_blocks(self, blocks: List[Dict]) -> List[Dict]:
        """
        –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª –ø–æ–∏—Å–∫–∞ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∫ –±–ª–æ–∫–∞–º –¥–æ–∫—É–º–µ–Ω—Ç–∞
        
        Args:
            blocks: –°–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            
        Returns:
            –ë–ª–æ–∫–∏ —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        """
        processed_blocks = []
        
        for block in blocks:
            processed_block = block.copy()
            
            text_content = block.get('text', block.get('content', ''))
            if text_content:
                # –ü–æ–∏—Å–∫ —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π
                regex_matches = self._find_regex_matches(text_content)
                
                # –ü–æ–∏—Å–∫ —Å –ø–æ–º–æ—â—å—é NLP —Å–µ—Ä–≤–∏—Å–∞ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
                nlp_matches = self._find_nlp_matches(text_content)
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                all_matches = regex_matches + nlp_matches
                
                # –ù–ï–¢ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ - –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞–ø–∏—Å–∞–Ω—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ!
                if all_matches:
                    processed_block['sensitive_patterns'] = all_matches
            
            processed_blocks.append(processed_block)
        
        return processed_blocks
    
    def _find_regex_matches(self, text: str) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        """
        matches = []
        
        for category, category_patterns in self.patterns.items():
            for pattern_info in category_patterns:
                pattern = pattern_info['pattern']
                confidence = pattern_info['confidence']
                description = pattern_info['description']
                
                try:
                    for match in re.finditer(pattern, text):
                        matches.append({
                            'category': category,
                            'original_value': match.group(),
                            'uuid': str(uuid.uuid4()),
                            'position': {
                                'start': match.start(),
                                'end': match.end()
                            },
                            'confidence': confidence,
                            'source': 'regex',
                            'description': description
                        })
                except re.error as e:
                    print(f"–û—à–∏–±–∫–∞ –≤ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–º –≤—ã—Ä–∞–∂–µ–Ω–∏–∏ {pattern}: {e}")
                    continue
        
        return matches
    
    def _find_nlp_matches(self, text: str) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é NLP —Å–µ—Ä–≤–∏—Å–∞
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –æ—Ç NLP —Å–µ—Ä–≤–∏—Å–∞
        """
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ NLP —Å–µ—Ä–≤–∏—Å—É
            response = requests.post(
                f"{self.nlp_service_url}/analyze_text",
                json={"text": text},
                timeout=5
            )
            
            if response.status_code == 200:
                nlp_data = response.json()
                
                matches = []
                for entity in nlp_data.get('entities', []):
                    matches.append({
                        'category': entity.get('label', 'unknown').lower(),
                        'original_value': entity.get('text', ''),
                        'uuid': str(uuid.uuid4()),
                        'position': {
                            'start': entity.get('start', 0),
                            'end': entity.get('end', 0)
                        },
                        'confidence': entity.get('confidence', 0.5),
                        'source': 'nlp',
                        'description': f"NLP: {entity.get('label', 'Unknown')}"
                    })
                
                return matches
                
        except requests.exceptions.RequestException as e:
            print(f"NLP —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ NLP —Å–µ—Ä–≤–∏—Å—É: {e}")
        
        return []
    
    def _remove_duplicate_matches(self, matches: List[Dict]) -> List[Dict]:
        """
        –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ –ø–æ–∑–∏—Ü–∏–∏ —Å –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–µ–π –ø–æ –¥–ª–∏–Ω–µ —á–∏—Å–ª–∞
        
        Args:
            matches: –°–ø–∏—Å–æ–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
            
        Returns:
            –°–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        """
        unique_matches = []
        seen_positions = {}  # –ø–æ–∑–∏—Ü–∏—è -> –ª—É—á—à–∏–π match
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É: –¥–ª–∏–Ω–∞ —á–∏—Å–ª–∞ (—É–±—ã–≤–∞–Ω–∏–µ), –∑–∞—Ç–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (—É–±—ã–≤–∞–Ω–∏–µ)
        def match_priority(match):
            value = match.get('original_value', '')
            # –°—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–ª–∏–Ω—ã
            digit_length = len(''.join(filter(str.isdigit, value)))
            confidence = match.get('confidence', 0)
            return (digit_length, confidence)
        
        matches.sort(key=match_priority, reverse=True)
        
        print(f"üîç [DEBUG] –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É:")
        for i, match in enumerate(matches):
            value = match.get('original_value', '')
            digit_length = len(''.join(filter(str.isdigit, value)))
            confidence = match.get('confidence', 0)
            category = match.get('category', 'unknown')
            print(f"   {i+1}. {category.upper()}: '{value}' (—Ü–∏—Ñ—Ä: {digit_length}, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence})")
        
        for match in matches:
            position = match.get('position', {})
            pos_key = (position.get('start', 0), position.get('end', 0))
            
            if pos_key not in seen_positions:
                # –ü–µ—Ä–≤–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –¥–ª—è —ç—Ç–æ–π –ø–æ–∑–∏—Ü–∏–∏ - –ø—Ä–∏–Ω–∏–º–∞–µ–º
                seen_positions[pos_key] = match
                unique_matches.append(match)
                print(f"‚úÖ [DEBUG] –ü—Ä–∏–Ω—è—Ç–æ: {match.get('category', 'unknown').upper()} '{match.get('original_value', '')}' (–ø–æ–∑–∏—Ü–∏—è {pos_key})")
            else:
                # –£–∂–µ –µ—Å—Ç—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –¥–ª—è —ç—Ç–æ–π –ø–æ–∑–∏—Ü–∏–∏ - –æ—Ç–∫–ª–æ–Ω—è–µ–º
                existing = seen_positions[pos_key]
                print(f"‚ùå [DEBUG] –û—Ç–∫–ª–æ–Ω–µ–Ω–æ: {match.get('category', 'unknown').upper()} '{match.get('original_value', '')}' (–¥—É–±–ª–∏–∫–∞—Ç {existing.get('category', 'unknown').upper()})")
        
        return unique_matches
    
    def find_sensitive_data(self, text: str) -> List[Dict]:
        """
        –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–µ–∫—Å—Ç–µ
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (–ë–ï–ó —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ - –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏!)
        """
        regex_matches = self._find_regex_matches(text)
        nlp_matches = self._find_nlp_matches(text)
        
        all_matches = regex_matches + nlp_matches
        # –ù–ï–¢ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ - –ø—Ä–∞–≤–∏–ª–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞–ø–∏—Å–∞–Ω—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ!
        return all_matches
    
    def generate_report(self, processed_blocks: List[Dict]) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            processed_blocks: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –±–ª–æ–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            
        Returns:
            –û—Ç—á–µ—Ç —Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        report = {
            'total_blocks': len(processed_blocks),
            'blocks_with_sensitive_data': 0,
            'pattern_statistics': {},
            'confidence_distribution': {
                'high': 0,  # > 0.8
                'medium': 0,  # 0.5 - 0.8
                'low': 0    # < 0.5
            },
            'source_statistics': {
                'regex': 0,
                'nlp': 0
            }
        }
        
        total_patterns = 0
        
        for block in processed_blocks:
            if 'sensitive_patterns' in block and block['sensitive_patterns']:
                report['blocks_with_sensitive_data'] += 1
                
                for pattern in block['sensitive_patterns']:
                    total_patterns += 1
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                    category = pattern.get('category', 'unknown')
                    if category not in report['pattern_statistics']:
                        report['pattern_statistics'][category] = 0
                    report['pattern_statistics'][category] += 1
                    
                    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                    confidence = pattern.get('confidence', 0.5)
                    if confidence > 0.8:
                        report['confidence_distribution']['high'] += 1
                    elif confidence > 0.5:
                        report['confidence_distribution']['medium'] += 1
                    else:
                        report['confidence_distribution']['low'] += 1
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
                    source = pattern.get('source', 'regex')
                    if source in report['source_statistics']:
                        report['source_statistics'][source] += 1
        
        report['total_patterns_found'] = total_patterns
        
        return report
    
    def validate_patterns(self) -> Dict[str, Any]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        """
        validation_report = {
            'valid_patterns': 0,
            'invalid_patterns': 0,
            'categories': list(self.patterns.keys()),
            'errors': []
        }
        
        for category, patterns_list in self.patterns.items():
            for i, pattern_info in enumerate(patterns_list):
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Ä–µ–≥—É–ª—è—Ä–Ω–æ–≥–æ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
                    re.compile(pattern_info['pattern'])
                    validation_report['valid_patterns'] += 1
                except re.error as e:
                    validation_report['invalid_patterns'] += 1
                    validation_report['errors'].append({
                        'category': category,
                        'pattern_index': i,
                        'pattern': pattern_info['pattern'],
                        'error': str(e)
                    })
        
        return validation_report